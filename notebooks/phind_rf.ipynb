{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efcdbd1d-163b-4dc0-9b88-d4e5fea57768",
   "metadata": {},
   "source": [
    "# Reinforcment Learning Using Policy Optimisation\n",
    "\n",
    "Instead of estimating the Q-value of the state, we will directly optimize the policy, however without\n",
    "MCTS search.\n",
    "\n",
    "In other words, the agent recieves state of the form $(board, card)$ and returns a probability\n",
    "distribution over **allowed actions** (achieved by masking out forbidden actions and rescaling\n",
    "probabilities). Then, based on the probability distribution, the move is chosen.\n",
    "\n",
    "Inspired by [this phind answer](https://www.phind.com/search?cache=4fb75c5b-c572-479b-9d6c-58df1ff67f52&fbclid=IwAR2lIRiaSEG0jXs3_CVScUe-Gl74HFeKY1I63eyImOhpr8tzuYSRto-lk2Q)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980160b2-005a-4923-93c5-0a3a6ad6eb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pip install -U pip\n",
    "%pip install install 'git+https://github.com/balgot/mathematico.git#egg=mathematico&subdirectory=game'\n",
    "%pip install torch torchview torch-summary graphviz numpy matplotlib tqdm wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b9ae250-9d46-48cf-9227-efdcf7328a46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from collections import deque, namedtuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5643b9-d43b-4b8f-8153-716a4f8f8dc4",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "The implemented algorithm is PPO (Proximal Policy Optimisation). After playing sufficient number of moves, the agent learns the updated policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "849fd791-504f-4a99-ab15-b858d9fb6f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STATE_SIZE = 25 + 1  # 25 positions on the board + 1 card\n",
    "ACTION_SIZE = 25\n",
    "\n",
    "config = {\n",
    "    \"seed\": 0,\n",
    "    \"episodes\": 100_000,\n",
    "    \"lr\": 1e-3,\n",
    "    \"gamma\": 0.99,\n",
    "    \"epsilon\": 0.5,\n",
    "    \"epsilon_min\": 0.01,\n",
    "    \"epsilon_decay\": 0.995,\n",
    "    \"memory_size\": 1_000,\n",
    "    \"batch_size\": 1,\n",
    "    \"decay_epochs\": 1_000,\n",
    "}\n",
    "\n",
    "random.seed(config[\"seed\"])\n",
    "torch.random.manual_seed(config[\"seed\"])\n",
    "np.random.seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd0bf6-f719-49d5-8ee9-d55e719bbb41",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "To encourage the agent to play \"good\" moves and converge quicker, we use reward shaping, i.e. the reward is not awarded only at the end of the episode, but rather after each move as the difference of scores of pre- and post-move boards. Note that the sum of the partial scores is equal to the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7611a179-a7e6-49e1-9ef1-04eef35ba5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mathematico import Board\n",
    "\n",
    "\n",
    "class MathematicoEnv:\n",
    "    def __init__(self):\n",
    "        self.board = None\n",
    "        self.deck = None\n",
    "        self.move_idx = None\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.board = Board()\n",
    "        self.deck = [k for k in range(1, 13+1) for _ in range(4)]\n",
    "        random.shuffle(self.deck)\n",
    "        self.move_idx = 0\n",
    "        return self.board.grid, [ self.deck[self.move_idx] ]\n",
    "        \n",
    "    def step(self, action):\n",
    "        _score_before = self.board.score()\n",
    "        self.board.make_move(action, self.deck[self.move_idx])\n",
    "        self.move_idx += 1\n",
    "        _score_after = self.board.score()\n",
    "        return (self.board.grid, [ self.deck[self.move_idx] ]), _score_after - _score_before, self.move_idx >= 25, None\n",
    "        \n",
    "env = MathematicoEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb94606-100c-4799-b2cf-532d717c3e5d",
   "metadata": {},
   "source": [
    "## Replay Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3fead-e99d-40a3-9ed0-8ce84785e7ee",
   "metadata": {},
   "source": [
    "To keep track of previous moves, actions, next states and rewards, we will use the following class (effectively bounded queue):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "09eaaca2-feb5-418a-8f21-deea389a239d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'card', 'action', 'next_state', 'next_card', 'reward'))\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        transitions = random.sample(self.memory, batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        card_batch = torch.cat(batch.card)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        next_state_batch = torch.cat(batch.next_state)\n",
    "        next_card_batch = torch.cat(batch.next_card)\n",
    "        return state_batch, card_batch, action_batch, reward_batch, next_state_batch, next_card_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf17971-3df0-4d05-a31c-39bff3e7e333",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "fe41c8ec-77f3-4505-9392-ead947b1baf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Flatten: 1-1                           [-1, 25]                  --\n",
      "├─Sequential: 1-2                        [-1, 25]                  --\n",
      "|    └─Linear: 2-1                       [-1, 128]                 3,456\n",
      "|    └─Tanh: 2-2                         [-1, 128]                 --\n",
      "|    └─Linear: 2-3                       [-1, 25]                  3,225\n",
      "==========================================================================================\n",
      "Total params: 6,681\n",
      "Trainable params: 6,681\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.01\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.03\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size=STATE_SIZE, output_size=ACTION_SIZE):\n",
    "        super(DQN, self).__init__()\n",
    "        self.flat = nn.Flatten()\n",
    "        self.pipe = nn.Sequential(*[\n",
    "            nn.Linear(26, 128), nn.Tanh(),\n",
    "            # nn.Linear(128, 128), nn.ReLU(),\n",
    "            # nn.Linear(128, 128), nn.ReLU(),\n",
    "            # nn.Linear(128, 128), nn.ReLU(),\n",
    "            # nn.Linear(128, 128), nn.ReLU(),\n",
    "            # nn.Linear(128, 128), nn.ReLU(),\n",
    "            # nn.Linear(128, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 25)\n",
    "        ])\n",
    "        \n",
    "\n",
    "    def forward(self, board, card):\n",
    "        x = self.flat(board)\n",
    "        mask = x\n",
    "       \n",
    "        x = torch.cat((x, card), dim=1).float()        \n",
    "        x = self.pipe(x)\n",
    "        \n",
    "        x = torch.where(mask == 0, x, -float('inf'))  # apply mask\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "_batch = 1\n",
    "_board = Board().grid\n",
    "_board[0][0] = 1\n",
    "_card = 1\n",
    "_board = torch.tensor([_board] * _batch)\n",
    "_card = torch.tensor([[_card]] * _batch)\n",
    "summary(DQN(), input_data=(_board, _card));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a56d3d-d000-4a99-a4f0-5264a7acc100",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "037d571e-67b7-4771-9883-d589b19e1273",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:0')"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.epsilon = config[\"epsilon\"]\n",
    "        self.memory = ReplayMemory(config[\"memory_size\"])\n",
    "        self.policy_net = DQN().to(dev)\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=config[\"lr\"])\n",
    "        \n",
    "        self.target_net = DQN().to(dev)\n",
    "        self.update_target_network()\n",
    "        self.target_net.eval()\n",
    "\n",
    "    def act(self, state, card):\n",
    "        \"\"\"Play a move given state.\"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            available = [5*row + col for row in range(5) for col in range(5) if state[0][row][col] == 0]\n",
    "            return torch.tensor([random.choice(available)], device=dev)\n",
    "        with torch.no_grad():\n",
    "            distr = self.policy_net(state, card)\n",
    "            distr = torch.distributions.Categorical(distr)\n",
    "            sample = distr.sample()\n",
    "            return sample\n",
    "\n",
    "    def learn(self):\n",
    "        if len(self.memory) < config[\"batch_size\"]:\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\\nLearning\\n=========\\n\")\n",
    "        _sample = self.memory.sample(config[\"batch_size\"])\n",
    "        print(\"sample\", _sample)\n",
    "        print(f\"{self.policy_net.pipe[0].weight=}\")\n",
    "        print(f\"{self.target_net.pipe[0].weight=}\")\n",
    "        state_batch, card_batch, action_batch, reward_batch, next_state_batch, next_card_batch = _sample\n",
    "        # q_values = torch.index_select(self.policy_net(state_batch, card_batch), 0, action_batch.to(dev).long())\n",
    "        q_values = self.policy_net(state_batch, card_batch)\n",
    "        q_values = torch.gather(q_values, 1, action_batch.unsqueeze(1)).squeeze(1)\n",
    "        print(f\"{q_values.shape=}\\n\\t{q_values=}\")\n",
    "        print(f\"{action_batch.shape=}\")\n",
    "        next_q_values = self.target_net(next_state_batch, next_card_batch).max(1)[0].detach()\n",
    "        print(f\"{next_q_values.shape=}\\n\\t{next_q_values=}\")\n",
    "        print(f\"\\t\\t{self.target_net(next_state_batch, next_card_batch)=}\")\n",
    "        expected_q_values = ((next_q_values * config[\"gamma\"]) + reward_batch)\n",
    "        print(f\"{expected_q_values.shape=}\\n\\t{expected_q_values=}\")\n",
    "        \n",
    "        loss = F.mse_loss(q_values, expected_q_values)\n",
    "        print(f\"{loss=}\")\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(config[\"epsilon_min\"], self.epsilon * config[\"epsilon_decay\"])\n",
    "\n",
    "        \n",
    "agent = Agent()\n",
    "agent.act(torch.tensor([Board().grid], device=dev), torch.tensor([[1]], device=dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02726b-24ae-4cb2-8aec-4869ea6dadc4",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c1e8d463-01db-48c6-9d7d-92dc5e933340",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219558c57c7741a7a7a4a9c413f720c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Episode:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([8], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0452], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0652], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0301, 0.0506, 0.0523, 0.0365, 0.0455, 0.0449, 0.0394, 0.0356, 0.0000,\n",
      "         0.0367, 0.0381, 0.0373, 0.0363, 0.0426, 0.0540, 0.0310, 0.0652, 0.0387,\n",
      "         0.0338, 0.0400, 0.0495, 0.0495, 0.0342, 0.0404, 0.0380]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0645], device='cuda:0')\n",
      "loss=tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([8], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1923],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0103],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0245],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1473],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0148],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1814]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0474], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0652], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0301, 0.0506, 0.0523, 0.0365, 0.0455, 0.0449, 0.0394, 0.0356, 0.0000,\n",
      "         0.0367, 0.0381, 0.0373, 0.0363, 0.0426, 0.0540, 0.0310, 0.0652, 0.0387,\n",
      "         0.0338, 0.0400, 0.0495, 0.0495, 0.0342, 0.0404, 0.0380]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0645], device='cuda:0')\n",
      "loss=tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([8], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1913],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0093],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0255],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1483],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0138],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1805]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0496], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0652], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0301, 0.0506, 0.0523, 0.0365, 0.0455, 0.0449, 0.0394, 0.0356, 0.0000,\n",
      "         0.0367, 0.0381, 0.0373, 0.0363, 0.0426, 0.0540, 0.0310, 0.0652, 0.0387,\n",
      "         0.0338, 0.0400, 0.0495, 0.0495, 0.0342, 0.0404, 0.0380]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0645], device='cuda:0')\n",
      "loss=tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([8], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1903],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0083],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0265],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1493],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0129],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1797]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0519], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0652], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0301, 0.0506, 0.0523, 0.0365, 0.0455, 0.0449, 0.0394, 0.0356, 0.0000,\n",
      "         0.0367, 0.0381, 0.0373, 0.0363, 0.0426, 0.0540, 0.0310, 0.0652, 0.0387,\n",
      "         0.0338, 0.0400, 0.0495, 0.0495, 0.0342, 0.0404, 0.0380]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0645], device='cuda:0')\n",
      "loss=tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([15], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [3., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1893],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0074],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0275],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1503],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0119],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1792]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0311], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0928], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0205, 0.0488, 0.0491, 0.0355, 0.0527, 0.0470, 0.0286, 0.0324, 0.0000,\n",
      "         0.0392, 0.0382, 0.0378, 0.0272, 0.0506, 0.0928, 0.0000, 0.0808, 0.0385,\n",
      "         0.0215, 0.0309, 0.0618, 0.0561, 0.0260, 0.0435, 0.0406]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0919], device='cuda:0')\n",
      "loss=tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([20], device='cuda:0'), tensor([170.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1893],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0066],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0283],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1503],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0122],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1786]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0722], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0902], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0399, 0.0147, 0.0687, 0.0340, 0.0531, 0.0357, 0.0310, 0.0609, 0.0000,\n",
      "         0.0715, 0.0454, 0.0568, 0.0484, 0.0353, 0.0000, 0.0000, 0.0525, 0.0327,\n",
      "         0.0612, 0.0492, 0.0000, 0.0680, 0.0902, 0.0297, 0.0213]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([170.0892], device='cuda:0')\n",
      "loss=tensor(28905.7949, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [3., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([14], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1888],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0071],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0278],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1508],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0127],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1792]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0931], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1303], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0222, 0.0228, 0.0571, 0.0297, 0.0571, 0.0449, 0.0204, 0.0447, 0.0000,\n",
      "         0.0382, 0.0505, 0.0436, 0.0441, 0.0318, 0.0000, 0.0000, 0.1303, 0.0337,\n",
      "         0.0218, 0.0473, 0.0722, 0.0777, 0.0469, 0.0441, 0.0189]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.1290], device='cuda:0')\n",
      "loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([20], device='cuda:0'), tensor([170.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1884],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0076],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0273],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1513],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0132],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1796]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0912], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0902], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0399, 0.0147, 0.0687, 0.0340, 0.0531, 0.0357, 0.0310, 0.0609, 0.0000,\n",
      "         0.0715, 0.0454, 0.0568, 0.0484, 0.0353, 0.0000, 0.0000, 0.0525, 0.0327,\n",
      "         0.0612, 0.0492, 0.0000, 0.0680, 0.0902, 0.0297, 0.0213]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([170.0892], device='cuda:0')\n",
      "loss=tensor(28899.3516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([8], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1877],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0082],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0267],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1519],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0138],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1802]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0592], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0652], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0301, 0.0506, 0.0523, 0.0365, 0.0455, 0.0449, 0.0394, 0.0356, 0.0000,\n",
      "         0.0367, 0.0381, 0.0373, 0.0363, 0.0426, 0.0540, 0.0310, 0.0652, 0.0387,\n",
      "         0.0338, 0.0400, 0.0495, 0.0495, 0.0342, 0.0404, 0.0380]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0645], device='cuda:0')\n",
      "loss=tensor(2.8384e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([20], device='cuda:0'), tensor([170.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1872],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0088],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0261],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1525],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0144],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1808]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1206], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0902], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0399, 0.0147, 0.0687, 0.0340, 0.0531, 0.0357, 0.0310, 0.0609, 0.0000,\n",
      "         0.0715, 0.0454, 0.0568, 0.0484, 0.0353, 0.0000, 0.0000, 0.0525, 0.0327,\n",
      "         0.0612, 0.0492, 0.0000, 0.0680, 0.0902, 0.0297, 0.0213]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([170.0892], device='cuda:0')\n",
      "loss=tensor(28889.3301, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([15], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [3., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1865],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0095],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0254],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1532],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0150],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1815]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0378], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0928], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0205, 0.0488, 0.0491, 0.0355, 0.0527, 0.0470, 0.0286, 0.0324, 0.0000,\n",
      "         0.0392, 0.0382, 0.0378, 0.0272, 0.0506, 0.0928, 0.0000, 0.0808, 0.0385,\n",
      "         0.0215, 0.0309, 0.0618, 0.0561, 0.0260, 0.0435, 0.0406]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0919], device='cuda:0')\n",
      "loss=tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([3], device='cuda:0'), tensor([-10.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1858],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0101],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0248],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1538],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0156],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1821]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1190], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1244], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0835, 0.0638, 0.0000, 0.0485, 0.0000,\n",
      "         0.1125, 0.0836, 0.0747, 0.1244, 0.0756, 0.0000, 0.0000, 0.0000, 0.0255,\n",
      "         0.0000, 0.0952, 0.0000, 0.0545, 0.0399, 0.0322, 0.0862]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-9.8769], device='cuda:0')\n",
      "loss=tensor(99.9168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([16], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0204,  0.1938,  0.0053,  ...,  0.0792,  0.1091,  0.1861],\n",
      "        [ 0.1468, -0.0720,  0.0619,  ...,  0.1861, -0.0947, -0.0107],\n",
      "        [ 0.0786,  0.0169,  0.1604,  ..., -0.1782, -0.0468,  0.0242],\n",
      "        ...,\n",
      "        [-0.0467, -0.1457,  0.1124,  ...,  0.0521, -0.1706, -0.1544],\n",
      "        [ 0.0765,  0.1077, -0.1418,  ...,  0.1711, -0.0177,  0.0162],\n",
      "        [-0.1512,  0.1577, -0.0735,  ..., -0.1720, -0.0550, -0.1827]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0542], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0565, 0.0136, 0.1028, 0.0682, 0.0492, 0.0356, 0.0236, 0.0504, 0.0000,\n",
      "         0.0680, 0.0383, 0.0626, 0.0463, 0.0393, 0.0000, 0.0000, 0.0000, 0.0242,\n",
      "         0.0579, 0.0462, 0.0000, 0.0882, 0.0693, 0.0312, 0.0287]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.1018], device='cuda:0')\n",
      "loss=tensor(401.9054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([19], device='cuda:0'), tensor([80.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0208,  0.1943,  0.0057,  ...,  0.0792,  0.1091,  0.1863],\n",
      "        [ 0.1472, -0.0715,  0.0624,  ...,  0.1861, -0.0947, -0.0112],\n",
      "        [ 0.0781,  0.0165,  0.1599,  ..., -0.1782, -0.0468,  0.0238],\n",
      "        ...,\n",
      "        [-0.0472, -0.1462,  0.1120,  ...,  0.0521, -0.1706, -0.1550],\n",
      "        [ 0.0770,  0.1082, -0.1414,  ...,  0.1711, -0.0177,  0.0168],\n",
      "        [-0.1516,  0.1573, -0.0739,  ..., -0.1720, -0.0550, -0.1827]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0933], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1376], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.1008, 0.0699, 0.0000, 0.0524, 0.0000,\n",
      "         0.1188, 0.1082, 0.0731, 0.1376, 0.0850, 0.0000, 0.0000, 0.0000, 0.0245,\n",
      "         0.0000, 0.0000, 0.0000, 0.0560, 0.0429, 0.0373, 0.0934]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([80.1363], device='cuda:0')\n",
      "loss=tensor(6406.8745, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [3., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([14], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0214,  0.1949,  0.0063,  ...,  0.0792,  0.1091,  0.1868],\n",
      "        [ 0.1476, -0.0711,  0.0628,  ...,  0.1861, -0.0947, -0.0116],\n",
      "        [ 0.0776,  0.0160,  0.1594,  ..., -0.1782, -0.0468,  0.0233],\n",
      "        ...,\n",
      "        [-0.0467, -0.1457,  0.1125,  ...,  0.0521, -0.1706, -0.1551],\n",
      "        [ 0.0766,  0.1077, -0.1418,  ...,  0.1711, -0.0177,  0.0170],\n",
      "        [-0.1513,  0.1576, -0.0736,  ..., -0.1720, -0.0550, -0.1827]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1423], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1303], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0222, 0.0228, 0.0571, 0.0297, 0.0571, 0.0449, 0.0204, 0.0447, 0.0000,\n",
      "         0.0382, 0.0505, 0.0436, 0.0441, 0.0318, 0.0000, 0.0000, 0.1303, 0.0337,\n",
      "         0.0218, 0.0473, 0.0722, 0.0777, 0.0469, 0.0441, 0.0189]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.1290], device='cuda:0')\n",
      "loss=tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  2.],\n",
      "         [ 0.,  5.,  8.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'), tensor([5], device='cuda:0'), tensor([-20.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  0.,  1.,  2.],\n",
      "         [ 0.,  5.,  8.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[7.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0220,  0.1954,  0.0069,  ...,  0.0792,  0.1091,  0.1872],\n",
      "        [ 0.1480, -0.0707,  0.0632,  ...,  0.1861, -0.0947, -0.0121],\n",
      "        [ 0.0771,  0.0155,  0.1589,  ..., -0.1782, -0.0468,  0.0229],\n",
      "        ...,\n",
      "        [-0.0463, -0.1453,  0.1129,  ...,  0.0521, -0.1706, -0.1551],\n",
      "        [ 0.0762,  0.1074, -0.1422,  ...,  0.1711, -0.0177,  0.0171],\n",
      "        [-0.1510,  0.1579, -0.0733,  ..., -0.1720, -0.0550, -0.1827]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1190], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1675], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.1183, 0.0000, 0.0000, 0.0846, 0.0000,\n",
      "         0.0000, 0.1616, 0.0000, 0.0000, 0.1675, 0.0000, 0.0000, 0.0000, 0.0384,\n",
      "         0.0000, 0.0000, 0.0000, 0.0912, 0.1259, 0.1126, 0.0999]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-19.8342], device='cuda:0')\n",
      "loss=tensor(398.1291, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'), tensor([9], device='cuda:0'), tensor([-120.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  2.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[5.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0225,  0.1959,  0.0074,  ...,  0.0792,  0.1091,  0.1876],\n",
      "        [ 0.1486, -0.0701,  0.0638,  ...,  0.1861, -0.0947, -0.0124],\n",
      "        [ 0.0775,  0.0159,  0.1593,  ..., -0.1782, -0.0468,  0.0226],\n",
      "        ...,\n",
      "        [-0.0459, -0.1449,  0.1133,  ...,  0.0521, -0.1706, -0.1552],\n",
      "        [ 0.0759,  0.1071, -0.1424,  ...,  0.1711, -0.0177,  0.0173],\n",
      "        [-0.1508,  0.1581, -0.0731,  ..., -0.1720, -0.0550, -0.1827]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1207], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1551], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.1039, 0.0833, 0.0000, 0.0638, 0.0000,\n",
      "         0.0000, 0.1215, 0.0936, 0.1551, 0.1035, 0.0000, 0.0000, 0.0000, 0.0292,\n",
      "         0.0000, 0.0000, 0.0000, 0.0632, 0.0485, 0.0443, 0.0902]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-119.8464], device='cuda:0')\n",
      "loss=tensor(14392.1074, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([8], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0225,  0.1959,  0.0074,  ...,  0.0792,  0.1091,  0.1876],\n",
      "        [ 0.1492, -0.0695,  0.0644,  ...,  0.1861, -0.0947, -0.0127],\n",
      "        [ 0.0779,  0.0163,  0.1597,  ..., -0.1782, -0.0468,  0.0223],\n",
      "        ...,\n",
      "        [-0.0459, -0.1448,  0.1133,  ...,  0.0521, -0.1706, -0.1553],\n",
      "        [ 0.0754,  0.1066, -0.1430,  ...,  0.1711, -0.0177,  0.0173],\n",
      "        [-0.1510,  0.1579, -0.0733,  ..., -0.1720, -0.0550, -0.1827]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0661], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0652], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0301, 0.0506, 0.0523, 0.0365, 0.0455, 0.0449, 0.0394, 0.0356, 0.0000,\n",
      "         0.0367, 0.0381, 0.0373, 0.0363, 0.0426, 0.0540, 0.0310, 0.0652, 0.0387,\n",
      "         0.0338, 0.0400, 0.0495, 0.0495, 0.0342, 0.0404, 0.0380]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0645], device='cuda:0')\n",
      "loss=tensor(2.5552e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'), tensor([2], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0225,  0.1959,  0.0074,  ...,  0.0792,  0.1091,  0.1875],\n",
      "        [ 0.1498, -0.0689,  0.0650,  ...,  0.1861, -0.0947, -0.0130],\n",
      "        [ 0.0783,  0.0166,  0.1601,  ..., -0.1782, -0.0468,  0.0220],\n",
      "        ...,\n",
      "        [-0.0458, -0.1448,  0.1134,  ...,  0.0521, -0.1706, -0.1554],\n",
      "        [ 0.0749,  0.1061, -0.1435,  ...,  0.1711, -0.0177,  0.0172],\n",
      "        [-0.1513,  0.1576, -0.0736,  ..., -0.1720, -0.0550, -0.1827]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0505], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.1028, 0.0774, 0.0824, 0.0194, 0.0473, 0.0000,\n",
      "         0.0675, 0.1004, 0.0766, 0.0740, 0.0620, 0.0000, 0.0000, 0.0000, 0.0167,\n",
      "         0.0000, 0.0861, 0.0000, 0.0658, 0.0392, 0.0495, 0.0329]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.8982], device='cuda:0')\n",
      "loss=tensor(3593.8420, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([20], device='cuda:0'), tensor([170.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0225,  0.1959,  0.0074,  ...,  0.0792,  0.1091,  0.1875],\n",
      "        [ 0.1504, -0.0683,  0.0655,  ...,  0.1861, -0.0947, -0.0133],\n",
      "        [ 0.0788,  0.0172,  0.1604,  ..., -0.1782, -0.0468,  0.0217],\n",
      "        ...,\n",
      "        [-0.0457, -0.1447,  0.1135,  ...,  0.0521, -0.1706, -0.1556],\n",
      "        [ 0.0744,  0.1056, -0.1439,  ...,  0.1711, -0.0177,  0.0171],\n",
      "        [-0.1515,  0.1574, -0.0738,  ..., -0.1720, -0.0550, -0.1827]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.3003], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0902], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0399, 0.0147, 0.0687, 0.0340, 0.0531, 0.0357, 0.0310, 0.0609, 0.0000,\n",
      "         0.0715, 0.0454, 0.0568, 0.0484, 0.0353, 0.0000, 0.0000, 0.0525, 0.0327,\n",
      "         0.0612, 0.0492, 0.0000, 0.0680, 0.0902, 0.0297, 0.0213]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([170.0892], device='cuda:0')\n",
      "loss=tensor(28828.2949, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'), tensor([2], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0225,  0.1959,  0.0074,  ...,  0.0792,  0.1091,  0.1874],\n",
      "        [ 0.1509, -0.0678,  0.0660,  ...,  0.1861, -0.0947, -0.0138],\n",
      "        [ 0.0793,  0.0177,  0.1607,  ..., -0.1782, -0.0468,  0.0211],\n",
      "        ...,\n",
      "        [-0.0457, -0.1447,  0.1135,  ...,  0.0521, -0.1706, -0.1561],\n",
      "        [ 0.0740,  0.1052, -0.1444,  ...,  0.1711, -0.0177,  0.0175],\n",
      "        [-0.1517,  0.1572, -0.0740,  ..., -0.1720, -0.0550, -0.1831]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0446], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.1028, 0.0774, 0.0824, 0.0194, 0.0473, 0.0000,\n",
      "         0.0675, 0.1004, 0.0766, 0.0740, 0.0620, 0.0000, 0.0000, 0.0000, 0.0167,\n",
      "         0.0000, 0.0861, 0.0000, 0.0658, 0.0392, 0.0495, 0.0329]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.8982], device='cuda:0')\n",
      "loss=tensor(3593.1365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([16], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0225,  0.1959,  0.0074,  ...,  0.0792,  0.1091,  0.1873],\n",
      "        [ 0.1514, -0.0673,  0.0665,  ...,  0.1861, -0.0947, -0.0143],\n",
      "        [ 0.0799,  0.0183,  0.1609,  ..., -0.1782, -0.0468,  0.0206],\n",
      "        ...,\n",
      "        [-0.0457, -0.1447,  0.1136,  ...,  0.0521, -0.1706, -0.1566],\n",
      "        [ 0.0736,  0.1048, -0.1447,  ...,  0.1711, -0.0177,  0.0179],\n",
      "        [-0.1518,  0.1571, -0.0742,  ..., -0.1720, -0.0550, -0.1835]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0624], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0565, 0.0136, 0.1028, 0.0682, 0.0492, 0.0356, 0.0236, 0.0504, 0.0000,\n",
      "         0.0680, 0.0383, 0.0626, 0.0463, 0.0393, 0.0000, 0.0000, 0.0000, 0.0242,\n",
      "         0.0579, 0.0462, 0.0000, 0.0882, 0.0693, 0.0312, 0.0287]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.1018], device='cuda:0')\n",
      "loss=tensor(401.5781, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([4], device='cuda:0'), tensor([-10.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[4.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0224,  0.1959,  0.0074,  ...,  0.0792,  0.1091,  0.1873],\n",
      "        [ 0.1518, -0.0669,  0.0669,  ...,  0.1861, -0.0947, -0.0148],\n",
      "        [ 0.0805,  0.0189,  0.1612,  ..., -0.1782, -0.0468,  0.0202],\n",
      "        ...,\n",
      "        [-0.0457, -0.1447,  0.1136,  ...,  0.0521, -0.1706, -0.1572],\n",
      "        [ 0.0733,  0.1045, -0.1451,  ...,  0.1711, -0.0177,  0.0183],\n",
      "        [-0.1520,  0.1569, -0.0743,  ..., -0.1720, -0.0550, -0.1835]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.2984], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.3120], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1101,\n",
      "         0.0000, 0.0000, 0.0000, 0.3093, 0.0000, 0.2686, 0.3120]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-9.6911], device='cuda:0')\n",
      "loss=tensor(99.7894, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([20], device='cuda:0'), tensor([170.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0229,  0.1964,  0.0079,  ...,  0.0792,  0.1091,  0.1876],\n",
      "        [ 0.1522, -0.0665,  0.0673,  ...,  0.1861, -0.0947, -0.0152],\n",
      "        [ 0.0801,  0.0185,  0.1607,  ..., -0.1782, -0.0468,  0.0198],\n",
      "        ...,\n",
      "        [-0.0457, -0.1447,  0.1137,  ...,  0.0521, -0.1706, -0.1576],\n",
      "        [ 0.0731,  0.1042, -0.1453,  ...,  0.1711, -0.0177,  0.0187],\n",
      "        [-0.1521,  0.1568, -0.0745,  ..., -0.1720, -0.0550, -0.1835]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.4037], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0902], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0399, 0.0147, 0.0687, 0.0340, 0.0531, 0.0357, 0.0310, 0.0609, 0.0000,\n",
      "         0.0715, 0.0454, 0.0568, 0.0484, 0.0353, 0.0000, 0.0000, 0.0525, 0.0327,\n",
      "         0.0612, 0.0492, 0.0000, 0.0680, 0.0902, 0.0297, 0.0213]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([170.0892], device='cuda:0')\n",
      "loss=tensor(28793.1699, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'), tensor([2], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0234,  0.1969,  0.0083,  ...,  0.0792,  0.1091,  0.1879],\n",
      "        [ 0.1526, -0.0661,  0.0676,  ...,  0.1861, -0.0947, -0.0158],\n",
      "        [ 0.0798,  0.0181,  0.1603,  ..., -0.1782, -0.0468,  0.0192],\n",
      "        ...,\n",
      "        [-0.0457, -0.1447,  0.1137,  ...,  0.0521, -0.1706, -0.1583],\n",
      "        [ 0.0729,  0.1040, -0.1455,  ...,  0.1711, -0.0177,  0.0193],\n",
      "        [-0.1522,  0.1567, -0.0746,  ..., -0.1720, -0.0550, -0.1839]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0337], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.1028, 0.0774, 0.0824, 0.0194, 0.0473, 0.0000,\n",
      "         0.0675, 0.1004, 0.0766, 0.0740, 0.0620, 0.0000, 0.0000, 0.0000, 0.0167,\n",
      "         0.0000, 0.0861, 0.0000, 0.0658, 0.0392, 0.0495, 0.0329]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.8982], device='cuda:0')\n",
      "loss=tensor(3591.8350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  4.,  7., 12.,  0.]]], device='cuda:0'), tensor([[8.]], device='cuda:0'), tensor([24], device='cuda:0'), tensor([-20.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  4.,  7., 12.,  8.]]], device='cuda:0'), tensor([[11.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0238,  0.1973,  0.0087,  ...,  0.0792,  0.1091,  0.1882],\n",
      "        [ 0.1529, -0.0658,  0.0679,  ...,  0.1861, -0.0947, -0.0164],\n",
      "        [ 0.0795,  0.0179,  0.1599,  ..., -0.1782, -0.0468,  0.0186],\n",
      "        ...,\n",
      "        [-0.0457, -0.1447,  0.1138,  ...,  0.0521, -0.1706, -0.1590],\n",
      "        [ 0.0727,  0.1038, -0.1456,  ...,  0.1711, -0.0177,  0.0199],\n",
      "        [-0.1523,  0.1566, -0.0747,  ..., -0.1720, -0.0550, -0.1842]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.7615], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([1.], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-19.0100], device='cuda:0')\n",
      "loss=tensor(390.9131, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([6], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0241,  0.1976,  0.0091,  ...,  0.0787,  0.1091,  0.1881],\n",
      "        [ 0.1533, -0.0655,  0.0682,  ...,  0.1866, -0.0947, -0.0169],\n",
      "        [ 0.0791,  0.0175,  0.1593,  ..., -0.1787, -0.0468,  0.0181],\n",
      "        ...,\n",
      "        [-0.0456, -0.1446,  0.1139,  ...,  0.0526, -0.1706, -0.1594],\n",
      "        [ 0.0724,  0.1036, -0.1459,  ...,  0.1705, -0.0177,  0.0203],\n",
      "        [-0.1524,  0.1565, -0.0748,  ..., -0.1720, -0.0550, -0.1845]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0152], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1207], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.1207, 0.0769, 0.0496, 0.0000, 0.0436, 0.0000,\n",
      "         0.0985, 0.0693, 0.0591, 0.1167, 0.0607, 0.0000, 0.0000, 0.0000, 0.0223,\n",
      "         0.0000, 0.0822, 0.0000, 0.0498, 0.0397, 0.0281, 0.0830]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.1195], device='cuda:0')\n",
      "loss=tensor(404.1814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 4., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([2], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 9., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 4., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[6.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0244,  0.1979,  0.0094,  ...,  0.0782,  0.1091,  0.1881],\n",
      "        [ 0.1536, -0.0651,  0.0685,  ...,  0.1871, -0.0947, -0.0174],\n",
      "        [ 0.0787,  0.0171,  0.1588,  ..., -0.1792, -0.0468,  0.0176],\n",
      "        ...,\n",
      "        [-0.0455, -0.1445,  0.1141,  ...,  0.0531, -0.1706, -0.1599],\n",
      "        [ 0.0722,  0.1034, -0.1461,  ...,  0.1700, -0.0177,  0.0207],\n",
      "        [-0.1524,  0.1565, -0.0749,  ..., -0.1720, -0.0550, -0.1847]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0272], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0863], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0406, 0.0256, 0.0000, 0.0863, 0.0305, 0.0757, 0.0297, 0.0399, 0.0301,\n",
      "         0.0302, 0.0583, 0.0529, 0.0421, 0.0568, 0.0417, 0.0417, 0.0000, 0.0266,\n",
      "         0.0435, 0.0404, 0.0428, 0.0438, 0.0332, 0.0437, 0.0438]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0854], device='cuda:0')\n",
      "loss=tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([6], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0247,  0.1982,  0.0096,  ...,  0.0777,  0.1091,  0.1881],\n",
      "        [ 0.1539, -0.0649,  0.0687,  ...,  0.1875, -0.0947, -0.0178],\n",
      "        [ 0.0784,  0.0167,  0.1584,  ..., -0.1797, -0.0468,  0.0172],\n",
      "        ...,\n",
      "        [-0.0454, -0.1444,  0.1142,  ...,  0.0536, -0.1706, -0.1602],\n",
      "        [ 0.0720,  0.1032, -0.1463,  ...,  0.1696, -0.0177,  0.0211],\n",
      "        [-0.1525,  0.1564, -0.0750,  ..., -0.1720, -0.0550, -0.1850]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0156], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1207], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.1207, 0.0769, 0.0496, 0.0000, 0.0436, 0.0000,\n",
      "         0.0985, 0.0693, 0.0591, 0.1167, 0.0607, 0.0000, 0.0000, 0.0000, 0.0223,\n",
      "         0.0000, 0.0822, 0.0000, 0.0498, 0.0397, 0.0281, 0.0830]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.1195], device='cuda:0')\n",
      "loss=tensor(404.1651, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([20], device='cuda:0'), tensor([170.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0250,  0.1984,  0.0099,  ...,  0.0773,  0.1091,  0.1881],\n",
      "        [ 0.1542, -0.0646,  0.0690,  ...,  0.1879, -0.0947, -0.0182],\n",
      "        [ 0.0781,  0.0164,  0.1580,  ..., -0.1801, -0.0468,  0.0168],\n",
      "        ...,\n",
      "        [-0.0453, -0.1442,  0.1143,  ...,  0.0540, -0.1706, -0.1606],\n",
      "        [ 0.0718,  0.1030, -0.1464,  ...,  0.1692, -0.0177,  0.0215],\n",
      "        [-0.1526,  0.1563, -0.0751,  ..., -0.1720, -0.0550, -0.1852]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.5852], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0902], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0399, 0.0147, 0.0687, 0.0340, 0.0531, 0.0357, 0.0310, 0.0609, 0.0000,\n",
      "         0.0715, 0.0454, 0.0568, 0.0484, 0.0353, 0.0000, 0.0000, 0.0525, 0.0327,\n",
      "         0.0612, 0.0492, 0.0000, 0.0680, 0.0902, 0.0297, 0.0213]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([170.0892], device='cuda:0')\n",
      "loss=tensor(28731.6055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  0.,  1.,  2.],\n",
      "         [ 7.,  5.,  8.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[6.]], device='cuda:0'), tensor([7], device='cuda:0'), tensor([-70.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0252,  0.1986,  0.0101,  ...,  0.0770,  0.1091,  0.1881],\n",
      "        [ 0.1544, -0.0643,  0.0692,  ...,  0.1883, -0.0947, -0.0188],\n",
      "        [ 0.0778,  0.0161,  0.1576,  ..., -0.1805, -0.0468,  0.0162],\n",
      "        ...,\n",
      "        [-0.0452, -0.1441,  0.1145,  ...,  0.0544, -0.1706, -0.1611],\n",
      "        [ 0.0717,  0.1028, -0.1466,  ...,  0.1688, -0.0177,  0.0221],\n",
      "        [-0.1526,  0.1563, -0.0751,  ..., -0.1720, -0.0550, -0.1857]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0897], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.2394], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.2023, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.2394, 0.0000, 0.0000, 0.0000, 0.0411,\n",
      "         0.0000, 0.0000, 0.0000, 0.1131, 0.1728, 0.1245, 0.1067]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-69.7630], device='cuda:0')\n",
      "loss=tensor(4879.3984, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 9., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[4.]], device='cuda:0'), tensor([4], device='cuda:0'), tensor([80.], device='cuda:0'), tensor([[[0., 0., 9., 0., 4.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0252,  0.1987,  0.0101,  ...,  0.0766,  0.1091,  0.1876],\n",
      "        [ 0.1547, -0.0641,  0.0694,  ...,  0.1887, -0.0947, -0.0194],\n",
      "        [ 0.0779,  0.0163,  0.1577,  ..., -0.1808, -0.0468,  0.0157],\n",
      "        ...,\n",
      "        [-0.0451, -0.1441,  0.1145,  ...,  0.0547, -0.1706, -0.1617],\n",
      "        [ 0.0715,  0.1027, -0.1468,  ...,  0.1685, -0.0177,  0.0227],\n",
      "        [-0.1527,  0.1562, -0.0752,  ..., -0.1720, -0.0550, -0.1861]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0305], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0955], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0506, 0.0397, 0.0000, 0.0755, 0.0000, 0.0310, 0.0318, 0.0625, 0.0955,\n",
      "         0.0190, 0.0713, 0.0000, 0.0512, 0.0000, 0.0483, 0.0678, 0.0000, 0.0000,\n",
      "         0.0599, 0.0493, 0.0557, 0.0485, 0.0298, 0.0576, 0.0549]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([80.0946], device='cuda:0')\n",
      "loss=tensor(6410.2520, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 9., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[4.]], device='cuda:0'), tensor([4], device='cuda:0'), tensor([80.], device='cuda:0'), tensor([[[0., 0., 9., 0., 4.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0252,  0.1987,  0.0098,  ...,  0.0763,  0.1091,  0.1869],\n",
      "        [ 0.1549, -0.0638,  0.0696,  ...,  0.1890, -0.0947, -0.0199],\n",
      "        [ 0.0781,  0.0165,  0.1575,  ..., -0.1811, -0.0468,  0.0152],\n",
      "        ...,\n",
      "        [-0.0450, -0.1440,  0.1146,  ...,  0.0550, -0.1706, -0.1622],\n",
      "        [ 0.0714,  0.1026, -0.1469,  ...,  0.1682, -0.0177,  0.0232],\n",
      "        [-0.1527,  0.1562, -0.0758,  ..., -0.1720, -0.0550, -0.1866]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0322], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0955], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0506, 0.0397, 0.0000, 0.0755, 0.0000, 0.0310, 0.0318, 0.0625, 0.0955,\n",
      "         0.0190, 0.0713, 0.0000, 0.0512, 0.0000, 0.0483, 0.0678, 0.0000, 0.0000,\n",
      "         0.0599, 0.0493, 0.0557, 0.0485, 0.0298, 0.0576, 0.0549]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([80.0946], device='cuda:0')\n",
      "loss=tensor(6409.9795, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[4.]], device='cuda:0'), tensor([21], device='cuda:0'), tensor([-70.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  4.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0252,  0.1987,  0.0093,  ...,  0.0760,  0.1091,  0.1860],\n",
      "        [ 0.1551, -0.0636,  0.0698,  ...,  0.1893, -0.0947, -0.0204],\n",
      "        [ 0.0783,  0.0166,  0.1569,  ..., -0.1814, -0.0468,  0.0147],\n",
      "        ...,\n",
      "        [-0.0450, -0.1440,  0.1147,  ...,  0.0553, -0.1706, -0.1626],\n",
      "        [ 0.0713,  0.1024, -0.1471,  ...,  0.1679, -0.0177,  0.0236],\n",
      "        [-0.1528,  0.1561, -0.0766,  ..., -0.1720, -0.0550, -0.1871]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.3034], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.4590], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1761,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4590, 0.3650]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-69.5456], device='cuda:0')\n",
      "loss=tensor(4878.8911, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([1], device='cuda:0'), tensor([160.], device='cuda:0'), tensor([[[ 2.,  3.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0247,  0.1982,  0.0086,  ...,  0.0758,  0.1091,  0.1850],\n",
      "        [ 0.1552, -0.0635,  0.0700,  ...,  0.1895, -0.0947, -0.0208],\n",
      "        [ 0.0787,  0.0171,  0.1567,  ..., -0.1817, -0.0468,  0.0143],\n",
      "        ...,\n",
      "        [-0.0451, -0.1441,  0.1146,  ...,  0.0555, -0.1706, -0.1631],\n",
      "        [ 0.0712,  0.1023, -0.1472,  ...,  0.1676, -0.0177,  0.0240],\n",
      "        [-0.1527,  0.1562, -0.0773,  ..., -0.1720, -0.0550, -0.1875]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0102], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1020], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0509, 0.0895, 0.0747, 0.0492, 0.0150, 0.0523, 0.0000,\n",
      "         0.0760, 0.1020, 0.0796, 0.0631, 0.0637, 0.0000, 0.0000, 0.0000, 0.0165,\n",
      "         0.0000, 0.0635, 0.0000, 0.0897, 0.0477, 0.0381, 0.0286]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([160.1010], device='cuda:0')\n",
      "loss=tensor(25629.0508, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([1], device='cuda:0'), tensor([160.], device='cuda:0'), tensor([[[ 2.,  3.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0242,  0.1977,  0.0079,  ...,  0.0755,  0.1091,  0.1842],\n",
      "        [ 0.1555, -0.0633,  0.0701,  ...,  0.1897, -0.0947, -0.0212],\n",
      "        [ 0.0792,  0.0174,  0.1565,  ..., -0.1819, -0.0468,  0.0139],\n",
      "        ...,\n",
      "        [-0.0453, -0.1442,  0.1146,  ...,  0.0558, -0.1706, -0.1635],\n",
      "        [ 0.0711,  0.1022, -0.1473,  ...,  0.1674, -0.0177,  0.0244],\n",
      "        [-0.1527,  0.1562, -0.0779,  ..., -0.1720, -0.0550, -0.1879]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0108], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1020], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0509, 0.0895, 0.0747, 0.0492, 0.0150, 0.0523, 0.0000,\n",
      "         0.0760, 0.1020, 0.0796, 0.0631, 0.0637, 0.0000, 0.0000, 0.0000, 0.0165,\n",
      "         0.0000, 0.0635, 0.0000, 0.0897, 0.0477, 0.0381, 0.0286]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([160.1010], device='cuda:0')\n",
      "loss=tensor(25628.8711, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 9., 0., 4.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([18], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[0., 0., 9., 0., 4.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0238,  0.1973,  0.0072,  ...,  0.0753,  0.1091,  0.1834],\n",
      "        [ 0.1558, -0.0632,  0.0702,  ...,  0.1900, -0.0947, -0.0215],\n",
      "        [ 0.0798,  0.0178,  0.1563,  ..., -0.1821, -0.0468,  0.0136],\n",
      "        ...,\n",
      "        [-0.0455, -0.1443,  0.1145,  ...,  0.0560, -0.1706, -0.1639],\n",
      "        [ 0.0710,  0.1022, -0.1474,  ...,  0.1672, -0.0177,  0.0248],\n",
      "        [-0.1526,  0.1563, -0.0785,  ..., -0.1720, -0.0550, -0.1882]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0526], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0920], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0330, 0.0535, 0.0000, 0.0794, 0.0000, 0.0423, 0.0383, 0.0637, 0.0851,\n",
      "         0.0317, 0.0920, 0.0000, 0.0554, 0.0000, 0.0810, 0.0380, 0.0000, 0.0000,\n",
      "         0.0000, 0.0473, 0.0629, 0.0699, 0.0253, 0.0654, 0.0356]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.0911], device='cuda:0')\n",
      "loss=tensor(401.5419, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 9., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 4., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[6.]], device='cuda:0'), tensor([13], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 9., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 6., 0.],\n",
      "         [0., 4., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[8.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0234,  0.1969,  0.0066,  ...,  0.0751,  0.1091,  0.1827],\n",
      "        [ 0.1561, -0.0630,  0.0703,  ...,  0.1902, -0.0947, -0.0218],\n",
      "        [ 0.0804,  0.0181,  0.1565,  ..., -0.1823, -0.0468,  0.0133],\n",
      "        ...,\n",
      "        [-0.0458, -0.1443,  0.1144,  ...,  0.0562, -0.1706, -0.1643],\n",
      "        [ 0.0710,  0.1021, -0.1475,  ...,  0.1670, -0.0177,  0.0251],\n",
      "        [-0.1525,  0.1563, -0.0793,  ..., -0.1720, -0.0550, -0.1886]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0517], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0736], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0443, 0.0203, 0.0000, 0.0652, 0.0438, 0.0595, 0.0360, 0.0577, 0.0509,\n",
      "         0.0295, 0.0577, 0.0288, 0.0396, 0.0000, 0.0736, 0.0492, 0.0000, 0.0308,\n",
      "         0.0426, 0.0487, 0.0432, 0.0468, 0.0268, 0.0586, 0.0462]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0729], device='cuda:0')\n",
      "loss=tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[7.]], device='cuda:0'), tensor([22], device='cuda:0'), tensor([70.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0231,  0.1965,  0.0060,  ...,  0.0750,  0.1091,  0.1820],\n",
      "        [ 0.1563, -0.0629,  0.0705,  ...,  0.1903, -0.0947, -0.0221],\n",
      "        [ 0.0809,  0.0184,  0.1567,  ..., -0.1825, -0.0468,  0.0130],\n",
      "        ...,\n",
      "        [-0.0460, -0.1444,  0.1144,  ...,  0.0564, -0.1706, -0.1647],\n",
      "        [ 0.0709,  0.1020, -0.1476,  ...,  0.1668, -0.0177,  0.0254],\n",
      "        [-0.1525,  0.1564, -0.0801,  ..., -0.1720, -0.0550, -0.1889]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1867], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.2908], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.2908, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0759,\n",
      "         0.0000, 0.0000, 0.0000, 0.2270, 0.0000, 0.1760, 0.2303]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([70.2879], device='cuda:0')\n",
      "loss=tensor(4914.1733, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[4.]], device='cuda:0'), tensor([21], device='cuda:0'), tensor([-70.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  4.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0224,  0.1958,  0.0053,  ...,  0.0748,  0.1091,  0.1813],\n",
      "        [ 0.1565, -0.0628,  0.0706,  ...,  0.1905, -0.0947, -0.0224],\n",
      "        [ 0.0816,  0.0191,  0.1573,  ..., -0.1826, -0.0468,  0.0128],\n",
      "        ...,\n",
      "        [-0.0466, -0.1449,  0.1139,  ...,  0.0565, -0.1706, -0.1653],\n",
      "        [ 0.0706,  0.1016, -0.1481,  ...,  0.1666, -0.0177,  0.0254],\n",
      "        [-0.1524,  0.1564, -0.0807,  ..., -0.1720, -0.0550, -0.1892]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1552], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.4590], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1761,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4590, 0.3650]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-69.5456], device='cuda:0')\n",
      "loss=tensor(4858.2012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([3], device='cuda:0'), tensor([-10.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0217,  0.1951,  0.0045,  ...,  0.0746,  0.1091,  0.1806],\n",
      "        [ 0.1567, -0.0627,  0.0706,  ...,  0.1906, -0.0947, -0.0226],\n",
      "        [ 0.0822,  0.0197,  0.1580,  ..., -0.1828, -0.0468,  0.0126],\n",
      "        ...,\n",
      "        [-0.0472, -0.1454,  0.1134,  ...,  0.0567, -0.1706, -0.1659],\n",
      "        [ 0.0702,  0.1012, -0.1485,  ...,  0.1665, -0.0177,  0.0255],\n",
      "        [-0.1523,  0.1565, -0.0813,  ..., -0.1720, -0.0550, -0.1894]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0654], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1244], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0835, 0.0638, 0.0000, 0.0485, 0.0000,\n",
      "         0.1125, 0.0836, 0.0747, 0.1244, 0.0756, 0.0000, 0.0000, 0.0000, 0.0255,\n",
      "         0.0000, 0.0952, 0.0000, 0.0545, 0.0399, 0.0322, 0.0862]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-9.8769], device='cuda:0')\n",
      "loss=tensor(98.8490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 4.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[8.]], device='cuda:0'), tensor([5], device='cuda:0'), tensor([70.], device='cuda:0'), tensor([[[ 4.,  0.,  9.,  0.,  4.],\n",
      "         [ 8.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0211,  0.1945,  0.0038,  ...,  0.0745,  0.1091,  0.1800],\n",
      "        [ 0.1570, -0.0625,  0.0708,  ...,  0.1908, -0.0947, -0.0229],\n",
      "        [ 0.0828,  0.0203,  0.1586,  ..., -0.1829, -0.0468,  0.0124],\n",
      "        ...,\n",
      "        [-0.0477, -0.1459,  0.1130,  ...,  0.0568, -0.1706, -0.1664],\n",
      "        [ 0.0698,  0.1009, -0.1488,  ...,  0.1664, -0.0177,  0.0255],\n",
      "        [-0.1523,  0.1565, -0.0819,  ..., -0.1720, -0.0550, -0.1897]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0438], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.2009], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0467, 0.0000, 0.1486, 0.0000, 0.0000, 0.0624, 0.1367, 0.0664,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0611, 0.0000, 0.0000,\n",
      "         0.0000, 0.1941, 0.0000, 0.0000, 0.0000, 0.2009, 0.0832]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([70.1989], device='cuda:0')\n",
      "loss=tensor(4921.7314, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 4.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[8.]], device='cuda:0'), tensor([5], device='cuda:0'), tensor([70.], device='cuda:0'), tensor([[[ 4.,  0.,  9.,  0.,  4.],\n",
      "         [ 8.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0205,  0.1939,  0.0032,  ...,  0.0744,  0.1091,  0.1794],\n",
      "        [ 0.1571, -0.0624,  0.0709,  ...,  0.1909, -0.0947, -0.0231],\n",
      "        [ 0.0831,  0.0209,  0.1590,  ..., -0.1830, -0.0468,  0.0123],\n",
      "        ...,\n",
      "        [-0.0482, -0.1463,  0.1125,  ...,  0.0569, -0.1706, -0.1669],\n",
      "        [ 0.0696,  0.1005, -0.1491,  ...,  0.1662, -0.0177,  0.0256],\n",
      "        [-0.1521,  0.1565, -0.0824,  ..., -0.1720, -0.0550, -0.1899]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0479], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.2009], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0467, 0.0000, 0.1486, 0.0000, 0.0000, 0.0624, 0.1367, 0.0664,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0611, 0.0000, 0.0000,\n",
      "         0.0000, 0.1941, 0.0000, 0.0000, 0.0000, 0.2009, 0.0832]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([70.1989], device='cuda:0')\n",
      "loss=tensor(4921.1597, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([16], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0200,  0.1934,  0.0026,  ...,  0.0743,  0.1091,  0.1789],\n",
      "        [ 0.1571, -0.0623,  0.0709,  ...,  0.1910, -0.0947, -0.0233],\n",
      "        [ 0.0831,  0.0213,  0.1592,  ..., -0.1831, -0.0468,  0.0121],\n",
      "        ...,\n",
      "        [-0.0487, -0.1467,  0.1121,  ...,  0.0570, -0.1706, -0.1674],\n",
      "        [ 0.0693,  0.1003, -0.1494,  ...,  0.1661, -0.0177,  0.0256],\n",
      "        [-0.1517,  0.1565, -0.0828,  ..., -0.1720, -0.0550, -0.1901]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0679], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0565, 0.0136, 0.1028, 0.0682, 0.0492, 0.0356, 0.0236, 0.0504, 0.0000,\n",
      "         0.0680, 0.0383, 0.0626, 0.0463, 0.0393, 0.0000, 0.0000, 0.0000, 0.0242,\n",
      "         0.0579, 0.0462, 0.0000, 0.0882, 0.0693, 0.0312, 0.0287]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.1018], device='cuda:0')\n",
      "loss=tensor(401.3561, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'), tensor([0], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 2.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[11.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0195,  0.1929,  0.0021,  ...,  0.0742,  0.1091,  0.1784],\n",
      "        [ 0.1570, -0.0621,  0.0709,  ...,  0.1911, -0.0947, -0.0234],\n",
      "        [ 0.0830,  0.0218,  0.1594,  ..., -0.1832, -0.0468,  0.0120],\n",
      "        ...,\n",
      "        [-0.0492, -0.1470,  0.1117,  ...,  0.0571, -0.1706, -0.1678],\n",
      "        [ 0.0690,  0.1000, -0.1497,  ...,  0.1660, -0.0177,  0.0257],\n",
      "        [-0.1513,  0.1565, -0.0832,  ..., -0.1720, -0.0550, -0.1901]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0481], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1021], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0143, 0.0801, 0.0553, 0.0687, 0.0467, 0.0254, 0.0788, 0.0000,\n",
      "         0.0852, 0.0524, 0.0627, 0.0402, 0.0398, 0.0000, 0.0000, 0.0000, 0.0244,\n",
      "         0.0462, 0.0570, 0.0000, 0.1021, 0.0707, 0.0283, 0.0217]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.8989], device='cuda:0')\n",
      "loss=tensor(3593.6504, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  2.],\n",
      "         [ 0.,  5.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[8.]], device='cuda:0'), tensor([12], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  2.],\n",
      "         [ 0.,  5.,  8.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0191,  0.1925,  0.0017,  ...,  0.0741,  0.1091,  0.1780],\n",
      "        [ 0.1570, -0.0620,  0.0709,  ...,  0.1912, -0.0947, -0.0236],\n",
      "        [ 0.0830,  0.0222,  0.1596,  ..., -0.1833, -0.0468,  0.0118],\n",
      "        ...,\n",
      "        [-0.0496, -0.1474,  0.1114,  ...,  0.0572, -0.1706, -0.1683],\n",
      "        [ 0.0688,  0.0998, -0.1499,  ...,  0.1659, -0.0177,  0.0257],\n",
      "        [-0.1510,  0.1565, -0.0836,  ..., -0.1720, -0.0550, -0.1900]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1735], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1423], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.1225, 0.1203, 0.0000, 0.0804, 0.0000,\n",
      "         0.0000, 0.1423, 0.0000, 0.0000, 0.1396, 0.0000, 0.0000, 0.0000, 0.0367,\n",
      "         0.0000, 0.0000, 0.0000, 0.0761, 0.0890, 0.0965, 0.0966]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.1408], device='cuda:0')\n",
      "loss=tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([20], device='cuda:0'), tensor([170.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0187,  0.1921,  0.0012,  ...,  0.0740,  0.1091,  0.1776],\n",
      "        [ 0.1569, -0.0619,  0.0709,  ...,  0.1913, -0.0947, -0.0237],\n",
      "        [ 0.0830,  0.0226,  0.1598,  ..., -0.1834, -0.0468,  0.0117],\n",
      "        ...,\n",
      "        [-0.0499, -0.1477,  0.1111,  ...,  0.0573, -0.1706, -0.1686],\n",
      "        [ 0.0686,  0.0996, -0.1502,  ...,  0.1659, -0.0177,  0.0258],\n",
      "        [-0.1507,  0.1565, -0.0839,  ..., -0.1720, -0.0550, -0.1900]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.8335], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0902], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0399, 0.0147, 0.0687, 0.0340, 0.0531, 0.0357, 0.0310, 0.0609, 0.0000,\n",
      "         0.0715, 0.0454, 0.0568, 0.0484, 0.0353, 0.0000, 0.0000, 0.0525, 0.0327,\n",
      "         0.0612, 0.0492, 0.0000, 0.0680, 0.0902, 0.0297, 0.0213]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([170.0892], device='cuda:0')\n",
      "loss=tensor(28647.5195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([8], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0183,  0.1917,  0.0009,  ...,  0.0739,  0.1091,  0.1773],\n",
      "        [ 0.1569, -0.0618,  0.0709,  ...,  0.1913, -0.0947, -0.0240],\n",
      "        [ 0.0830,  0.0229,  0.1599,  ..., -0.1835, -0.0468,  0.0115],\n",
      "        ...,\n",
      "        [-0.0503, -0.1479,  0.1108,  ...,  0.0574, -0.1706, -0.1691],\n",
      "        [ 0.0684,  0.0994, -0.1504,  ...,  0.1658, -0.0177,  0.0261],\n",
      "        [-0.1504,  0.1565, -0.0842,  ..., -0.1720, -0.0550, -0.1902]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0701], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0652], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0301, 0.0506, 0.0523, 0.0365, 0.0455, 0.0449, 0.0394, 0.0356, 0.0000,\n",
      "         0.0367, 0.0381, 0.0373, 0.0363, 0.0426, 0.0540, 0.0310, 0.0652, 0.0387,\n",
      "         0.0338, 0.0400, 0.0495, 0.0495, 0.0342, 0.0404, 0.0380]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0645], device='cuda:0')\n",
      "loss=tensor(3.1708e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[11.]], device='cuda:0'), tensor([18], device='cuda:0'), tensor([110.], device='cuda:0'), tensor([[[ 2.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0180,  0.1914,  0.0005,  ...,  0.0739,  0.1091,  0.1769],\n",
      "        [ 0.1569, -0.0617,  0.0709,  ...,  0.1914, -0.0947, -0.0243],\n",
      "        [ 0.0830,  0.0232,  0.1601,  ..., -0.1836, -0.0468,  0.0112],\n",
      "        ...,\n",
      "        [-0.0506, -0.1482,  0.1106,  ...,  0.0574, -0.1706, -0.1696],\n",
      "        [ 0.0683,  0.0992, -0.1505,  ...,  0.1657, -0.0177,  0.0264],\n",
      "        [-0.1502,  0.1565, -0.0845,  ..., -0.1720, -0.0550, -0.1904]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0394], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1192], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0133, 0.0584, 0.1192, 0.0699, 0.0421, 0.0176, 0.0503, 0.0000,\n",
      "         0.0658, 0.0800, 0.0739, 0.0841, 0.0566, 0.0000, 0.0000, 0.0000, 0.0125,\n",
      "         0.0000, 0.0688, 0.0000, 0.0774, 0.0444, 0.0329, 0.0329]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([110.1180], device='cuda:0')\n",
      "loss=tensor(12117.2959, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0., 11.],\n",
      "         [ 0.,  8.,  0.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[5.]], device='cuda:0'), tensor([10], device='cuda:0'), tensor([70.], device='cuda:0'), tensor([[[ 0.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8.,  0.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0177,  0.1911,  0.0002,  ...,  0.0738,  0.1091,  0.1767],\n",
      "        [ 0.1568, -0.0617,  0.0709,  ...,  0.1915, -0.0947, -0.0246],\n",
      "        [ 0.0834,  0.0235,  0.1602,  ..., -0.1836, -0.0468,  0.0111],\n",
      "        ...,\n",
      "        [-0.0510, -0.1484,  0.1104,  ...,  0.0575, -0.1706, -0.1702],\n",
      "        [ 0.0685,  0.0990, -0.1507,  ...,  0.1656, -0.0177,  0.0269],\n",
      "        [-0.1500,  0.1566, -0.0848,  ..., -0.1720, -0.0550, -0.1905]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0501], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1454], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0646, 0.0328, 0.0000, 0.1305, 0.0000, 0.0464, 0.0330, 0.1454, 0.0707,\n",
      "         0.0000, 0.0000, 0.0000, 0.0904, 0.0000, 0.0000, 0.0274, 0.0000, 0.0000,\n",
      "         0.0000, 0.1053, 0.0000, 0.0431, 0.0863, 0.0919, 0.0322]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([70.1440], device='cuda:0')\n",
      "loss=tensor(4913.1489, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 9., 0., 4.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([18], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[0., 0., 9., 0., 4.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 1.7437e-02,  1.9085e-01, -9.6867e-05,  ...,  7.3743e-02,\n",
      "          1.0914e-01,  1.7638e-01],\n",
      "        [ 1.5670e-01, -6.1601e-02,  7.1224e-02,  ...,  1.9154e-01,\n",
      "         -9.4661e-02, -2.4786e-02],\n",
      "        [ 8.3812e-02,  2.3717e-02,  1.6033e-01,  ..., -1.8368e-01,\n",
      "         -4.6805e-02,  1.0977e-02],\n",
      "        ...,\n",
      "        [-5.1459e-02, -1.4862e-01,  1.1015e-01,  ...,  5.7569e-02,\n",
      "         -1.7062e-01, -1.7076e-01],\n",
      "        [ 6.8632e-02,  9.8883e-02, -1.5075e-01,  ...,  1.6559e-01,\n",
      "         -1.7712e-02,  2.7388e-02],\n",
      "        [-1.4994e-01,  1.5656e-01, -8.5055e-02,  ..., -1.7195e-01,\n",
      "         -5.5046e-02, -1.9070e-01]], device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0805], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0920], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0330, 0.0535, 0.0000, 0.0794, 0.0000, 0.0423, 0.0383, 0.0637, 0.0851,\n",
      "         0.0317, 0.0920, 0.0000, 0.0554, 0.0000, 0.0810, 0.0380, 0.0000, 0.0000,\n",
      "         0.0000, 0.0473, 0.0629, 0.0699, 0.0253, 0.0654, 0.0356]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.0911], device='cuda:0')\n",
      "loss=tensor(400.4254, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 9., 0., 4.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([18], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[0., 0., 9., 0., 4.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 8., 0., 6., 0.],\n",
      "         [0., 4., 2., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0172,  0.1906, -0.0004,  ...,  0.0737,  0.1091,  0.1761],\n",
      "        [ 0.1566, -0.0615,  0.0715,  ...,  0.1916, -0.0947, -0.0250],\n",
      "        [ 0.0842,  0.0239,  0.1605,  ..., -0.1837, -0.0468,  0.0109],\n",
      "        ...,\n",
      "        [-0.0518, -0.1488,  0.1100,  ...,  0.0576, -0.1706, -0.1713],\n",
      "        [ 0.0688,  0.0988, -0.1508,  ...,  0.1655, -0.0177,  0.0278],\n",
      "        [-0.1498,  0.1566, -0.0857,  ..., -0.1720, -0.0550, -0.1909]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0848], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0920], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0330, 0.0535, 0.0000, 0.0794, 0.0000, 0.0423, 0.0383, 0.0637, 0.0851,\n",
      "         0.0317, 0.0920, 0.0000, 0.0554, 0.0000, 0.0810, 0.0380, 0.0000, 0.0000,\n",
      "         0.0000, 0.0473, 0.0629, 0.0699, 0.0253, 0.0654, 0.0356]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.0911], device='cuda:0')\n",
      "loss=tensor(400.2520, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 4.,  2.,  9.,  0.,  4.],\n",
      "         [ 8.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'), tensor([23], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 4.,  2.,  9.,  0.,  4.],\n",
      "         [ 8.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3., 10.,  0.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0170,  0.1904, -0.0007,  ...,  0.0736,  0.1091,  0.1759],\n",
      "        [ 0.1566, -0.0615,  0.0718,  ...,  0.1916, -0.0947, -0.0252],\n",
      "        [ 0.0845,  0.0242,  0.1608,  ..., -0.1838, -0.0468,  0.0108],\n",
      "        ...,\n",
      "        [-0.0522, -0.1490,  0.1098,  ...,  0.0577, -0.1706, -0.1717],\n",
      "        [ 0.0689,  0.0986, -0.1508,  ...,  0.1655, -0.0177,  0.0283],\n",
      "        [-0.1498,  0.1566, -0.0865,  ..., -0.1720, -0.0550, -0.1910]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.3137], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.2179], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.2062, 0.0000, 0.0000, 0.0939, 0.1350, 0.1106,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1155, 0.0000, 0.0000,\n",
      "         0.0000, 0.2179, 0.0000, 0.0000, 0.0000, 0.0000, 0.1210]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.7842], device='cuda:0')\n",
      "loss=tensor(3611.7595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'), tensor([9], device='cuda:0'), tensor([-120.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  2.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[5.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0168,  0.1902, -0.0009,  ...,  0.0736,  0.1091,  0.1757],\n",
      "        [ 0.1567, -0.0613,  0.0722,  ...,  0.1917, -0.0947, -0.0253],\n",
      "        [ 0.0844,  0.0241,  0.1608,  ..., -0.1838, -0.0468,  0.0106],\n",
      "        ...,\n",
      "        [-0.0525, -0.1491,  0.1096,  ...,  0.0577, -0.1706, -0.1722],\n",
      "        [ 0.0691,  0.0985, -0.1508,  ...,  0.1654, -0.0177,  0.0287],\n",
      "        [-0.1498,  0.1565, -0.0873,  ..., -0.1720, -0.0550, -0.1912]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0372], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1551], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.1039, 0.0833, 0.0000, 0.0638, 0.0000,\n",
      "         0.0000, 0.1215, 0.0936, 0.1551, 0.1035, 0.0000, 0.0000, 0.0000, 0.0292,\n",
      "         0.0000, 0.0000, 0.0000, 0.0632, 0.0485, 0.0443, 0.0902]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-119.8464], device='cuda:0')\n",
      "loss=tensor(14372.0918, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  8.,  0.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[11.]], device='cuda:0'), tensor([9], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 0.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0., 11.],\n",
      "         [ 0.,  8.,  0.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[5.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0166,  0.1900, -0.0012,  ...,  0.0736,  0.1091,  0.1755],\n",
      "        [ 0.1570, -0.0610,  0.0726,  ...,  0.1917, -0.0947, -0.0255],\n",
      "        [ 0.0842,  0.0240,  0.1608,  ..., -0.1839, -0.0468,  0.0105],\n",
      "        ...,\n",
      "        [-0.0529, -0.1493,  0.1094,  ...,  0.0577, -0.1706, -0.1726],\n",
      "        [ 0.0691,  0.0982, -0.1510,  ...,  0.1654, -0.0177,  0.0290],\n",
      "        [-0.1500,  0.1564, -0.0880,  ..., -0.1720, -0.0550, -0.1913]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0429], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1378], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0589, 0.0317, 0.0000, 0.1283, 0.0000, 0.0542, 0.0260, 0.1378, 0.0628,\n",
      "         0.0000, 0.0503, 0.0000, 0.0899, 0.0000, 0.0000, 0.0362, 0.0000, 0.0000,\n",
      "         0.0000, 0.0898, 0.0000, 0.0445, 0.0753, 0.0827, 0.0315]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.8636], device='cuda:0')\n",
      "loss=tensor(3588.7825, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 4.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([22], device='cuda:0'), tensor([-70.], device='cuda:0'), tensor([[[ 4.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[8.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0164,  0.1898, -0.0014,  ...,  0.0735,  0.1091,  0.1753],\n",
      "        [ 0.1573, -0.0608,  0.0732,  ...,  0.1918, -0.0947, -0.0256],\n",
      "        [ 0.0841,  0.0240,  0.1608,  ..., -0.1839, -0.0468,  0.0104],\n",
      "        ...,\n",
      "        [-0.0532, -0.1495,  0.1092,  ...,  0.0578, -0.1706, -0.1729],\n",
      "        [ 0.0690,  0.0980, -0.1512,  ...,  0.1654, -0.0177,  0.0293],\n",
      "        [-0.1502,  0.1562, -0.0886,  ..., -0.1720, -0.0550, -0.1915]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1720], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1618], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0654, 0.0000, 0.1377, 0.0000, 0.0740, 0.0784, 0.1508, 0.0876,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0388, 0.0000, 0.0000,\n",
      "         0.0000, 0.1618, 0.0000, 0.0000, 0.0000, 0.1423, 0.0631]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-69.8398], device='cuda:0')\n",
      "loss=tensor(4901.6602, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([8], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0163,  0.1896, -0.0016,  ...,  0.0735,  0.1091,  0.1752],\n",
      "        [ 0.1572, -0.0605,  0.0735,  ...,  0.1918, -0.0947, -0.0257],\n",
      "        [ 0.0835,  0.0239,  0.1604,  ..., -0.1839, -0.0468,  0.0103],\n",
      "        ...,\n",
      "        [-0.0533, -0.1497,  0.1091,  ...,  0.0578, -0.1706, -0.1732],\n",
      "        [ 0.0690,  0.0977, -0.1514,  ...,  0.1653, -0.0177,  0.0295],\n",
      "        [-0.1495,  0.1561, -0.0891,  ..., -0.1720, -0.0550, -0.1916]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0705], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0652], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0301, 0.0506, 0.0523, 0.0365, 0.0455, 0.0449, 0.0394, 0.0356, 0.0000,\n",
      "         0.0367, 0.0381, 0.0373, 0.0363, 0.0426, 0.0540, 0.0310, 0.0652, 0.0387,\n",
      "         0.0338, 0.0400, 0.0495, 0.0495, 0.0342, 0.0404, 0.0380]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0645], device='cuda:0')\n",
      "loss=tensor(3.5698e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[4.]], device='cuda:0'), tensor([21], device='cuda:0'), tensor([-70.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  4.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0162,  0.1895, -0.0018,  ...,  0.0735,  0.1091,  0.1751],\n",
      "        [ 0.1571, -0.0603,  0.0738,  ...,  0.1918, -0.0947, -0.0259],\n",
      "        [ 0.0829,  0.0239,  0.1600,  ..., -0.1840, -0.0468,  0.0102],\n",
      "        ...,\n",
      "        [-0.0535, -0.1499,  0.1090,  ...,  0.0578, -0.1706, -0.1735],\n",
      "        [ 0.0690,  0.0975, -0.1515,  ...,  0.1653, -0.0177,  0.0298],\n",
      "        [-0.1488,  0.1560, -0.0895,  ..., -0.1720, -0.0550, -0.1917]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0423], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.4590], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1761,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4590, 0.3650]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-69.5456], device='cuda:0')\n",
      "loss=tensor(4842.4819, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [3., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([22], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [3., 0., 0., 0., 0.],\n",
      "         [0., 0., 3., 0., 0.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0162,  0.1893, -0.0019,  ...,  0.0734,  0.1091,  0.1749],\n",
      "        [ 0.1570, -0.0601,  0.0740,  ...,  0.1918, -0.0947, -0.0260],\n",
      "        [ 0.0824,  0.0239,  0.1597,  ..., -0.1840, -0.0468,  0.0102],\n",
      "        ...,\n",
      "        [-0.0536, -0.1501,  0.1089,  ...,  0.0579, -0.1706, -0.1738],\n",
      "        [ 0.0690,  0.0973, -0.1517,  ...,  0.1653, -0.0177,  0.0300],\n",
      "        [-0.1482,  0.1559, -0.0899,  ..., -0.1720, -0.0550, -0.1917]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0305], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1133], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0223, 0.0463, 0.0480, 0.0376, 0.0483, 0.0512, 0.0318, 0.0352, 0.0000,\n",
      "         0.0413, 0.0442, 0.0364, 0.0236, 0.0570, 0.1133, 0.0000, 0.0736, 0.0441,\n",
      "         0.0184, 0.0322, 0.0530, 0.0506, 0.0000, 0.0406, 0.0511]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.1122], device='cuda:0')\n",
      "loss=tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([4], device='cuda:0'), tensor([-10.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  1.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[4.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0161,  0.1892, -0.0021,  ...,  0.0734,  0.1091,  0.1748],\n",
      "        [ 0.1569, -0.0599,  0.0743,  ...,  0.1919, -0.0947, -0.0260],\n",
      "        [ 0.0820,  0.0238,  0.1594,  ..., -0.1840, -0.0468,  0.0101],\n",
      "        ...,\n",
      "        [-0.0538, -0.1503,  0.1087,  ...,  0.0579, -0.1706, -0.1741],\n",
      "        [ 0.0689,  0.0971, -0.1519,  ...,  0.1653, -0.0177,  0.0302],\n",
      "        [-0.1477,  0.1558, -0.0902,  ..., -0.1720, -0.0550, -0.1918]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0999], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.3120], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1101,\n",
      "         0.0000, 0.0000, 0.0000, 0.3093, 0.0000, 0.2686, 0.3120]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-9.6911], device='cuda:0')\n",
      "loss=tensor(95.8639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [3., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([14], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0160,  0.1891, -0.0022,  ...,  0.0734,  0.1091,  0.1747],\n",
      "        [ 0.1569, -0.0598,  0.0745,  ...,  0.1919, -0.0947, -0.0261],\n",
      "        [ 0.0816,  0.0238,  0.1591,  ..., -0.1840, -0.0468,  0.0100],\n",
      "        ...,\n",
      "        [-0.0539, -0.1505,  0.1086,  ...,  0.0579, -0.1706, -0.1743],\n",
      "        [ 0.0689,  0.0970, -0.1520,  ...,  0.1652, -0.0177,  0.0304],\n",
      "        [-0.1472,  0.1558, -0.0905,  ..., -0.1720, -0.0550, -0.1919]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0890], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1303], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0222, 0.0228, 0.0571, 0.0297, 0.0571, 0.0449, 0.0204, 0.0447, 0.0000,\n",
      "         0.0382, 0.0505, 0.0436, 0.0441, 0.0318, 0.0000, 0.0000, 0.1303, 0.0337,\n",
      "         0.0218, 0.0473, 0.0722, 0.0777, 0.0469, 0.0441, 0.0189]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.1290], device='cuda:0')\n",
      "loss=tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([6], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0160,  0.1890, -0.0023,  ...,  0.0734,  0.1091,  0.1746],\n",
      "        [ 0.1568, -0.0596,  0.0747,  ...,  0.1919, -0.0947, -0.0262],\n",
      "        [ 0.0812,  0.0237,  0.1588,  ..., -0.1841, -0.0468,  0.0099],\n",
      "        ...,\n",
      "        [-0.0541, -0.1506,  0.1085,  ...,  0.0579, -0.1706, -0.1745],\n",
      "        [ 0.0689,  0.0968, -0.1520,  ...,  0.1652, -0.0177,  0.0305],\n",
      "        [-0.1468,  0.1557, -0.0908,  ..., -0.1720, -0.0550, -0.1919]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0177], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1207], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.1207, 0.0769, 0.0496, 0.0000, 0.0436, 0.0000,\n",
      "         0.0985, 0.0693, 0.0591, 0.1167, 0.0607, 0.0000, 0.0000, 0.0000, 0.0223,\n",
      "         0.0000, 0.0822, 0.0000, 0.0498, 0.0397, 0.0281, 0.0830]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.1195], device='cuda:0')\n",
      "loss=tensor(404.0805, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  0.,  0.],\n",
      "         [ 3., 12.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[8.]], device='cuda:0'), tensor([20], device='cuda:0'), tensor([100.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  0.,  0.],\n",
      "         [ 3., 12.,  0.,  0.,  0.],\n",
      "         [ 8.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[5.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0159,  0.1889, -0.0024,  ...,  0.0734,  0.1091,  0.1745],\n",
      "        [ 0.1568, -0.0594,  0.0749,  ...,  0.1919, -0.0947, -0.0263],\n",
      "        [ 0.0808,  0.0237,  0.1585,  ..., -0.1841, -0.0468,  0.0099],\n",
      "        ...,\n",
      "        [-0.0542, -0.1508,  0.1084,  ...,  0.0580, -0.1706, -0.1747],\n",
      "        [ 0.0689,  0.0967, -0.1521,  ...,  0.1652, -0.0177,  0.0307],\n",
      "        [-0.1464,  0.1557, -0.0910,  ..., -0.1720, -0.0550, -0.1920]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.3662], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1064], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0430, 0.0274, 0.0545, 0.1064, 0.0961, 0.0264, 0.0247, 0.0486, 0.0000,\n",
      "         0.0329, 0.0691, 0.0000, 0.0750, 0.0522, 0.0575, 0.0000, 0.0000, 0.0339,\n",
      "         0.0440, 0.0435, 0.0000, 0.0668, 0.0000, 0.0436, 0.0545]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([100.1053], device='cuda:0')\n",
      "loss=tensor(9947.8848, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[7.]], device='cuda:0'), tensor([22], device='cuda:0'), tensor([70.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  7.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0159,  0.1888, -0.0025,  ...,  0.0733,  0.1091,  0.1739],\n",
      "        [ 0.1568, -0.0592,  0.0751,  ...,  0.1919, -0.0947, -0.0265],\n",
      "        [ 0.0805,  0.0236,  0.1583,  ..., -0.1841, -0.0468,  0.0098],\n",
      "        ...,\n",
      "        [-0.0543, -0.1509,  0.1083,  ...,  0.0580, -0.1706, -0.1753],\n",
      "        [ 0.0689,  0.0966, -0.1522,  ...,  0.1652, -0.0177,  0.0311],\n",
      "        [-0.1461,  0.1556, -0.0913,  ..., -0.1720, -0.0550, -0.1927]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.3642], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.2908], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.2908, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0759,\n",
      "         0.0000, 0.0000, 0.0000, 0.2270, 0.0000, 0.1760, 0.2303]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([70.2879], device='cuda:0')\n",
      "loss=tensor(4889.3301, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 4.,  2.,  9., 12.,  4.],\n",
      "         [ 8.,  0.,  5.,  7., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [11.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3., 10., 13.]]], device='cuda:0'), tensor([[6.]], device='cuda:0'), tensor([19], device='cuda:0'), tensor([-20.], device='cuda:0'), tensor([[[ 4.,  2.,  9., 12.,  4.],\n",
      "         [ 8.,  0.,  5.,  7., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [11.,  4.,  2.,  1.,  6.],\n",
      "         [10.,  2.,  3., 10., 13.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0154,  0.1883, -0.0030,  ...,  0.0733,  0.1091,  0.1730],\n",
      "        [ 0.1568, -0.0591,  0.0753,  ...,  0.1920, -0.0947, -0.0268],\n",
      "        [ 0.0805,  0.0242,  0.1586,  ..., -0.1841, -0.0468,  0.0098],\n",
      "        ...,\n",
      "        [-0.0547, -0.1514,  0.1078,  ...,  0.0580, -0.1706, -0.1760],\n",
      "        [ 0.0684,  0.0960, -0.1528,  ...,  0.1652, -0.0177,  0.0311],\n",
      "        [-0.1457,  0.1556, -0.0915,  ..., -0.1720, -0.0550, -0.1934]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.6348], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([1.], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-19.0100], device='cuda:0')\n",
      "loss=tensor(385.9164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8.,  0.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'), tensor([12], device='cuda:0'), tensor([-40.], device='cuda:0'), tensor([[[ 0.,  0.,  9.,  0.,  4.],\n",
      "         [ 0.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[4.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0150,  0.1878, -0.0034,  ...,  0.0739,  0.1099,  0.1722],\n",
      "        [ 0.1569, -0.0589,  0.0755,  ...,  0.1927, -0.0939, -0.0270],\n",
      "        [ 0.0806,  0.0247,  0.1589,  ..., -0.1841, -0.0460,  0.0098],\n",
      "        ...,\n",
      "        [-0.0551, -0.1518,  0.1074,  ...,  0.0580, -0.1714, -0.1767],\n",
      "        [ 0.0679,  0.0954, -0.1534,  ...,  0.1652, -0.0185,  0.0311],\n",
      "        [-0.1459,  0.1550, -0.0917,  ..., -0.1727, -0.0558, -0.1940]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0643], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1321], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0897, 0.0477, 0.0000, 0.1297, 0.0000, 0.0621, 0.0525, 0.1192, 0.0781,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0367, 0.0000, 0.0000,\n",
      "         0.0000, 0.1321, 0.0000, 0.0000, 0.0780, 0.1261, 0.0481]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-39.8692], device='cuda:0')\n",
      "loss=tensor(1594.6876, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0., 10.,  0.],\n",
      "         [ 0.,  0.,  5.,  1.,  0.],\n",
      "         [ 5.,  9.,  0.,  0.,  8.],\n",
      "         [ 3., 12.,  0.,  0.,  0.],\n",
      "         [ 8.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([17], device='cuda:0'), tensor([-120.], device='cuda:0'), tensor([[[ 0.,  0.,  0., 10.,  0.],\n",
      "         [ 0.,  0.,  5.,  1.,  0.],\n",
      "         [ 5.,  9.,  0.,  0.,  8.],\n",
      "         [ 3., 12.,  1.,  0.,  0.],\n",
      "         [ 8.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[7.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0146,  0.1874, -0.0038,  ...,  0.0744,  0.1107,  0.1715],\n",
      "        [ 0.1569, -0.0587,  0.0756,  ...,  0.1935, -0.0931, -0.0272],\n",
      "        [ 0.0806,  0.0251,  0.1591,  ..., -0.1841, -0.0453,  0.0098],\n",
      "        ...,\n",
      "        [-0.0555, -0.1522,  0.1071,  ...,  0.0580, -0.1721, -0.1773],\n",
      "        [ 0.0675,  0.0949, -0.1539,  ...,  0.1651, -0.0192,  0.0311],\n",
      "        [-0.1461,  0.1544, -0.0918,  ..., -0.1735, -0.0566, -0.1945]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0551], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1626], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0370, 0.0345, 0.1174, 0.0000, 0.1626, 0.0714, 0.0618, 0.0000, 0.0000,\n",
      "         0.0656, 0.0000, 0.0000, 0.0722, 0.0685, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0446, 0.0589, 0.0000, 0.1330, 0.0000, 0.0474, 0.0252]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-119.8390], device='cuda:0')\n",
      "loss=tensor(14374.5977, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'), tensor([2], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0143,  0.1870, -0.0042,  ...,  0.0748,  0.1113,  0.1709],\n",
      "        [ 0.1570, -0.0586,  0.0757,  ...,  0.1941, -0.0925, -0.0274],\n",
      "        [ 0.0806,  0.0255,  0.1594,  ..., -0.1841, -0.0446,  0.0098],\n",
      "        ...,\n",
      "        [-0.0558, -0.1525,  0.1068,  ...,  0.0580, -0.1728, -0.1779],\n",
      "        [ 0.0671,  0.0944, -0.1543,  ...,  0.1651, -0.0199,  0.0312],\n",
      "        [-0.1462,  0.1539, -0.0919,  ..., -0.1741, -0.0572, -0.1949]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0171], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.1028, 0.0774, 0.0824, 0.0194, 0.0473, 0.0000,\n",
      "         0.0675, 0.1004, 0.0766, 0.0740, 0.0620, 0.0000, 0.0000, 0.0000, 0.0167,\n",
      "         0.0000, 0.0861, 0.0000, 0.0658, 0.0392, 0.0495, 0.0329]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.8982], device='cuda:0')\n",
      "loss=tensor(3589.8416, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([3], device='cuda:0'), tensor([-10.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0140,  0.1867, -0.0046,  ...,  0.0752,  0.1119,  0.1703],\n",
      "        [ 0.1571, -0.0584,  0.0757,  ...,  0.1947, -0.0919, -0.0276],\n",
      "        [ 0.0806,  0.0259,  0.1596,  ..., -0.1841, -0.0441,  0.0098],\n",
      "        ...,\n",
      "        [-0.0561, -0.1529,  0.1065,  ...,  0.0580, -0.1734, -0.1784],\n",
      "        [ 0.0667,  0.0940, -0.1548,  ...,  0.1651, -0.0205,  0.0312],\n",
      "        [-0.1463,  0.1534, -0.0920,  ..., -0.1747, -0.0578, -0.1953]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0580], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1244], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0835, 0.0638, 0.0000, 0.0485, 0.0000,\n",
      "         0.1125, 0.0836, 0.0747, 0.1244, 0.0756, 0.0000, 0.0000, 0.0000, 0.0255,\n",
      "         0.0000, 0.0952, 0.0000, 0.0545, 0.0399, 0.0322, 0.0862]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-9.8769], device='cuda:0')\n",
      "loss=tensor(98.7014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0., 10.,  0.],\n",
      "         [11., 11.,  5.,  1.,  0.],\n",
      "         [ 5.,  9.,  0.,  7.,  8.],\n",
      "         [ 3., 12.,  1., 13.,  0.],\n",
      "         [ 8.,  0.,  3., 13.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'), tensor([2], device='cuda:0'), tensor([-10.], device='cuda:0'), tensor([[[ 0.,  0., 10., 10.,  0.],\n",
      "         [11., 11.,  5.,  1.,  0.],\n",
      "         [ 5.,  9.,  0.,  7.,  8.],\n",
      "         [ 3., 12.,  1., 13.,  0.],\n",
      "         [ 8.,  0.,  3., 13.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0137,  0.1864, -0.0049,  ...,  0.0756,  0.1124,  0.1698],\n",
      "        [ 0.1572, -0.0582,  0.0758,  ...,  0.1952, -0.0914, -0.0277],\n",
      "        [ 0.0806,  0.0262,  0.1597,  ..., -0.1842, -0.0435,  0.0098],\n",
      "        ...,\n",
      "        [-0.0564, -0.1532,  0.1062,  ...,  0.0580, -0.1739, -0.1788],\n",
      "        [ 0.0664,  0.0936, -0.1551,  ...,  0.1651, -0.0210,  0.0312],\n",
      "        [-0.1464,  0.1530, -0.0921,  ..., -0.1753, -0.0583, -0.1957]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0726], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.3878], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0544, 0.0565, 0.0000, 0.0000, 0.3878, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0967, 0.0000, 0.0000, 0.1066, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0819, 0.0000, 0.1462, 0.0000, 0.0000, 0.0699]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-9.6161], device='cuda:0')\n",
      "loss=tensor(93.8713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'), tensor([0], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 2.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[11.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0134,  0.1861, -0.0051,  ...,  0.0759,  0.1129,  0.1693],\n",
      "        [ 0.1573, -0.0581,  0.0759,  ...,  0.1957, -0.0909, -0.0279],\n",
      "        [ 0.0807,  0.0265,  0.1599,  ..., -0.1842, -0.0430,  0.0098],\n",
      "        ...,\n",
      "        [-0.0566, -0.1534,  0.1059,  ...,  0.0580, -0.1744, -0.1793],\n",
      "        [ 0.0661,  0.0933, -0.1554,  ...,  0.1651, -0.0215,  0.0313],\n",
      "        [-0.1465,  0.1525, -0.0922,  ..., -0.1757, -0.0588, -0.1960]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0239], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1021], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0143, 0.0801, 0.0553, 0.0687, 0.0467, 0.0254, 0.0788, 0.0000,\n",
      "         0.0852, 0.0524, 0.0627, 0.0402, 0.0398, 0.0000, 0.0000, 0.0000, 0.0244,\n",
      "         0.0462, 0.0570, 0.0000, 0.1021, 0.0707, 0.0283, 0.0217]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.8989], device='cuda:0')\n",
      "loss=tensor(3590.7400, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'), tensor([2], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0132,  0.1859, -0.0054,  ...,  0.0762,  0.1134,  0.1689],\n",
      "        [ 0.1574, -0.0579,  0.0760,  ...,  0.1962, -0.0904, -0.0280],\n",
      "        [ 0.0807,  0.0268,  0.1601,  ..., -0.1842, -0.0426,  0.0098],\n",
      "        ...,\n",
      "        [-0.0568, -0.1537,  0.1057,  ...,  0.0580, -0.1748, -0.1796],\n",
      "        [ 0.0659,  0.0930, -0.1557,  ...,  0.1651, -0.0219,  0.0313],\n",
      "        [-0.1466,  0.1522, -0.0922,  ..., -0.1762, -0.0593, -0.1963]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0161], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.1028, 0.0774, 0.0824, 0.0194, 0.0473, 0.0000,\n",
      "         0.0675, 0.1004, 0.0766, 0.0740, 0.0620, 0.0000, 0.0000, 0.0000, 0.0167,\n",
      "         0.0000, 0.0861, 0.0000, 0.0658, 0.0392, 0.0495, 0.0329]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.8982], device='cuda:0')\n",
      "loss=tensor(3589.7251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  0.,  1.,  2.],\n",
      "         [ 0.,  5.,  8.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[7.]], device='cuda:0'), tensor([10], device='cuda:0'), tensor([-20.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  0.,  1.,  2.],\n",
      "         [ 7.,  5.,  8.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[6.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0130,  0.1856, -0.0056,  ...,  0.0765,  0.1138,  0.1685],\n",
      "        [ 0.1575, -0.0577,  0.0761,  ...,  0.1966, -0.0900, -0.0281],\n",
      "        [ 0.0807,  0.0270,  0.1602,  ..., -0.1842, -0.0422,  0.0098],\n",
      "        ...,\n",
      "        [-0.0570, -0.1539,  0.1055,  ...,  0.0580, -0.1752, -0.1800],\n",
      "        [ 0.0657,  0.0927, -0.1560,  ...,  0.1651, -0.0223,  0.0313],\n",
      "        [-0.1467,  0.1518, -0.0923,  ..., -0.1766, -0.0597, -0.1965]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1512], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1903], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.1389, 0.0000, 0.0000, 0.0809, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1896, 0.0000, 0.0000, 0.0000, 0.0347,\n",
      "         0.0000, 0.0000, 0.0000, 0.1214, 0.1903, 0.1241, 0.1200]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-19.8116], device='cuda:0')\n",
      "loss=tensor(398.5121, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'), tensor([0], device='cuda:0'), tensor([-60.], device='cuda:0'), tensor([[[ 2.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[11.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0128,  0.1854, -0.0058,  ...,  0.0767,  0.1141,  0.1681],\n",
      "        [ 0.1575, -0.0576,  0.0761,  ...,  0.1969, -0.0897, -0.0283],\n",
      "        [ 0.0807,  0.0272,  0.1603,  ..., -0.1842, -0.0418,  0.0098],\n",
      "        ...,\n",
      "        [-0.0572, -0.1541,  0.1053,  ...,  0.0579, -0.1756, -0.1803],\n",
      "        [ 0.0653,  0.0923, -0.1564,  ...,  0.1651, -0.0227,  0.0312],\n",
      "        [-0.1468,  0.1515, -0.0923,  ..., -0.1769, -0.0600, -0.1968]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0212], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1021], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0143, 0.0801, 0.0553, 0.0687, 0.0467, 0.0254, 0.0788, 0.0000,\n",
      "         0.0852, 0.0524, 0.0627, 0.0402, 0.0398, 0.0000, 0.0000, 0.0000, 0.0244,\n",
      "         0.0462, 0.0570, 0.0000, 0.1021, 0.0707, 0.0283, 0.0217]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-59.8989], device='cuda:0')\n",
      "loss=tensor(3590.4180, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([15], device='cuda:0'), tensor([0.], device='cuda:0'), tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [3., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[13.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0127,  0.1852, -0.0060,  ...,  0.0769,  0.1145,  0.1678],\n",
      "        [ 0.1576, -0.0576,  0.0762,  ...,  0.1973, -0.0893, -0.0283],\n",
      "        [ 0.0807,  0.0274,  0.1604,  ..., -0.1842, -0.0415,  0.0098],\n",
      "        ...,\n",
      "        [-0.0574, -0.1543,  0.1051,  ...,  0.0579, -0.1759, -0.1806],\n",
      "        [ 0.0650,  0.0920, -0.1567,  ...,  0.1651, -0.0230,  0.0312],\n",
      "        [-0.1469,  0.1513, -0.0924,  ..., -0.1773, -0.0604, -0.1970]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0554], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.0928], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0205, 0.0488, 0.0491, 0.0355, 0.0527, 0.0470, 0.0286, 0.0324, 0.0000,\n",
      "         0.0392, 0.0382, 0.0378, 0.0272, 0.0506, 0.0928, 0.0000, 0.0808, 0.0385,\n",
      "         0.0215, 0.0309, 0.0618, 0.0561, 0.0260, 0.0435, 0.0406]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([0.0919], device='cuda:0')\n",
      "loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([16], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0125,  0.1851, -0.0062,  ...,  0.0771,  0.1148,  0.1675],\n",
      "        [ 0.1576, -0.0575,  0.0762,  ...,  0.1976, -0.0890, -0.0284],\n",
      "        [ 0.0807,  0.0276,  0.1605,  ..., -0.1842, -0.0412,  0.0098],\n",
      "        ...,\n",
      "        [-0.0576, -0.1545,  0.1050,  ...,  0.0579, -0.1762, -0.1808],\n",
      "        [ 0.0648,  0.0917, -0.1570,  ...,  0.1651, -0.0233,  0.0311],\n",
      "        [-0.1469,  0.1510, -0.0924,  ..., -0.1776, -0.0607, -0.1972]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0706], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0565, 0.0136, 0.1028, 0.0682, 0.0492, 0.0356, 0.0236, 0.0504, 0.0000,\n",
      "         0.0680, 0.0383, 0.0626, 0.0463, 0.0393, 0.0000, 0.0000, 0.0000, 0.0242,\n",
      "         0.0579, 0.0462, 0.0000, 0.0882, 0.0693, 0.0312, 0.0287]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.1018], device='cuda:0')\n",
      "loss=tensor(401.2469, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0., 10.,  0.],\n",
      "         [ 0.,  0.,  5.,  1.,  0.],\n",
      "         [ 5.,  9.,  0.,  0.,  8.],\n",
      "         [ 3., 12.,  1.,  0.,  0.],\n",
      "         [ 8.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[7.]], device='cuda:0'), tensor([13], device='cuda:0'), tensor([-70.], device='cuda:0'), tensor([[[ 0.,  0.,  0., 10.,  0.],\n",
      "         [ 0.,  0.,  5.,  1.,  0.],\n",
      "         [ 5.,  9.,  0.,  7.,  8.],\n",
      "         [ 3., 12.,  1.,  0.,  0.],\n",
      "         [ 8.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[11.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0124,  0.1849, -0.0063,  ...,  0.0773,  0.1150,  0.1672],\n",
      "        [ 0.1577, -0.0574,  0.0762,  ...,  0.1978, -0.0888, -0.0285],\n",
      "        [ 0.0807,  0.0277,  0.1606,  ..., -0.1842, -0.0409,  0.0098],\n",
      "        ...,\n",
      "        [-0.0577, -0.1546,  0.1048,  ...,  0.0579, -0.1765, -0.1811],\n",
      "        [ 0.0645,  0.0914, -0.1573,  ...,  0.1651, -0.0236,  0.0311],\n",
      "        [-0.1470,  0.1508, -0.0925,  ..., -0.1778, -0.0609, -0.1973]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0795], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1427], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0386, 0.0344, 0.1327, 0.0000, 0.1327, 0.0713, 0.0732, 0.0000, 0.0000,\n",
      "         0.0729, 0.0000, 0.0000, 0.0827, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0544, 0.0691, 0.0000, 0.1427, 0.0000, 0.0626, 0.0326]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-69.8587], device='cuda:0')\n",
      "loss=tensor(4891.3521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[10.]], device='cuda:0'), tensor([13], device='cuda:0'), tensor([-70.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [12.,  9.,  6.,  1.,  2.],\n",
      "         [ 7.,  5.,  8., 10., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  3.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[7.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0122,  0.1848, -0.0064,  ...,  0.0775,  0.1153,  0.1670],\n",
      "        [ 0.1577, -0.0573,  0.0763,  ...,  0.1981, -0.0885, -0.0286],\n",
      "        [ 0.0807,  0.0279,  0.1607,  ..., -0.1842, -0.0407,  0.0098],\n",
      "        ...,\n",
      "        [-0.0578, -0.1548,  0.1047,  ...,  0.0579, -0.1768, -0.1813],\n",
      "        [ 0.0643,  0.0912, -0.1575,  ...,  0.1651, -0.0238,  0.0310],\n",
      "        [-0.1471,  0.1506, -0.0925,  ..., -0.1781, -0.0612, -0.1970]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1715], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.2316], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.2277, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0624,\n",
      "         0.0000, 0.0000, 0.0000, 0.1525, 0.2316, 0.1757, 0.1501]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-69.7707], device='cuda:0')\n",
      "loss=tensor(4891.9048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0., 10.,  0.],\n",
      "         [ 0.,  0.,  5.,  1.,  0.],\n",
      "         [ 5.,  9.,  0.,  7.,  8.],\n",
      "         [ 3., 12.,  1.,  0.,  0.],\n",
      "         [ 8.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[11.]], device='cuda:0'), tensor([5], device='cuda:0'), tensor([-70.], device='cuda:0'), tensor([[[ 0.,  0.,  0., 10.,  0.],\n",
      "         [11.,  0.,  5.,  1.,  0.],\n",
      "         [ 5.,  9.,  0.,  7.,  8.],\n",
      "         [ 3., 12.,  1.,  0.,  0.],\n",
      "         [ 8.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[11.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0121,  0.1846, -0.0066,  ...,  0.0776,  0.1155,  0.1667],\n",
      "        [ 0.1577, -0.0573,  0.0763,  ...,  0.1983, -0.0883, -0.0286],\n",
      "        [ 0.0808,  0.0282,  0.1609,  ..., -0.1842, -0.0405,  0.0099],\n",
      "        ...,\n",
      "        [-0.0579, -0.1549,  0.1046,  ...,  0.0579, -0.1770, -0.1815],\n",
      "        [ 0.0639,  0.0907, -0.1580,  ...,  0.1651, -0.0241,  0.0308],\n",
      "        [-0.1471,  0.1504, -0.0925,  ..., -0.1783, -0.0614, -0.1967]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0972], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1516], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0368, 0.0462, 0.1250, 0.0000, 0.1299, 0.0000, 0.0943, 0.0000, 0.0000,\n",
      "         0.0638, 0.0000, 0.0000, 0.0728, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0906, 0.0543, 0.0000, 0.1516, 0.0000, 0.0975, 0.0373]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-69.8499], device='cuda:0')\n",
      "loss=tensor(4892.5923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 2.,  3., 10.,  0.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([3], device='cuda:0'), tensor([-10.], device='cuda:0'), tensor([[[ 2.,  3., 10.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0., 11.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0119,  0.1845, -0.0068,  ...,  0.0778,  0.1157,  0.1663],\n",
      "        [ 0.1578, -0.0572,  0.0763,  ...,  0.1985, -0.0881, -0.0287],\n",
      "        [ 0.0809,  0.0286,  0.1612,  ..., -0.1842, -0.0403,  0.0099],\n",
      "        ...,\n",
      "        [-0.0581, -0.1550,  0.1045,  ...,  0.0579, -0.1772, -0.1816],\n",
      "        [ 0.0636,  0.0903, -0.1584,  ...,  0.1651, -0.0243,  0.0307],\n",
      "        [-0.1471,  0.1502, -0.0926,  ..., -0.1785, -0.0616, -0.1970]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0555], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1244], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0835, 0.0638, 0.0000, 0.0485, 0.0000,\n",
      "         0.1125, 0.0836, 0.0747, 0.1244, 0.0756, 0.0000, 0.0000, 0.0000, 0.0255,\n",
      "         0.0000, 0.0952, 0.0000, 0.0545, 0.0399, 0.0322, 0.0862]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-9.8769], device='cuda:0')\n",
      "loss=tensor(98.6519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 4.,  2.,  9., 12.,  4.],\n",
      "         [ 8.,  0.,  0.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3., 10., 13.]]], device='cuda:0'), tensor([[5.]], device='cuda:0'), tensor([7], device='cuda:0'), tensor([-70.], device='cuda:0'), tensor([[[ 4.,  2.,  9., 12.,  4.],\n",
      "         [ 8.,  0.,  5.,  0., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [ 0.,  4.,  2.,  1.,  0.],\n",
      "         [10.,  2.,  3., 10., 13.]]], device='cuda:0'), tensor([[7.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0118,  0.1843, -0.0069,  ...,  0.0779,  0.1159,  0.1658],\n",
      "        [ 0.1579, -0.0571,  0.0764,  ...,  0.1987, -0.0879, -0.0287],\n",
      "        [ 0.0811,  0.0289,  0.1614,  ..., -0.1842, -0.0401,  0.0100],\n",
      "        ...,\n",
      "        [-0.0582, -0.1551,  0.1044,  ...,  0.0578, -0.1774, -0.1818],\n",
      "        [ 0.0632,  0.0900, -0.1587,  ...,  0.1651, -0.0244,  0.0307],\n",
      "        [-0.1472,  0.1500, -0.0926,  ..., -0.1787, -0.0618, -0.1974]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0621], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.3471], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1679, 0.0000, 0.3471,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2372, 0.0000, 0.0000,\n",
      "         0.0000, 0.2477, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-69.6564], device='cuda:0')\n",
      "loss=tensor(4860.6660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  0.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([16], device='cuda:0'), tensor([20.], device='cuda:0'), tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  1.,  0.],\n",
      "         [ 0.,  0.,  0.,  0., 13.],\n",
      "         [ 3.,  9.,  0.,  0.,  0.],\n",
      "         [13.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[2.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0117,  0.1842, -0.0070,  ...,  0.0781,  0.1162,  0.1655],\n",
      "        [ 0.1573, -0.0573,  0.0761,  ...,  0.1978, -0.0888, -0.0287],\n",
      "        [ 0.0812,  0.0291,  0.1616,  ..., -0.1842, -0.0392,  0.0100],\n",
      "        ...,\n",
      "        [-0.0583, -0.1552,  0.1043,  ...,  0.0578, -0.1782, -0.1819],\n",
      "        [ 0.0630,  0.0897, -0.1590,  ...,  0.1654, -0.0236,  0.0307],\n",
      "        [-0.1472,  0.1499, -0.0926,  ..., -0.1788, -0.0619, -0.1977]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.0758], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1028], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0565, 0.0136, 0.1028, 0.0682, 0.0492, 0.0356, 0.0236, 0.0504, 0.0000,\n",
      "         0.0680, 0.0383, 0.0626, 0.0463, 0.0393, 0.0000, 0.0000, 0.0000, 0.0242,\n",
      "         0.0579, 0.0462, 0.0000, 0.0882, 0.0693, 0.0312, 0.0287]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([20.1018], device='cuda:0')\n",
      "loss=tensor(401.0386, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0., 10.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  1.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.],\n",
      "         [10.,  0.,  0.,  0.,  0.]]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([22], device='cuda:0'), tensor([80.], device='cuda:0'), tensor([[[ 0., 10.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  1.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.],\n",
      "         [10.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[5.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0116,  0.1841, -0.0071,  ...,  0.0783,  0.1164,  0.1651],\n",
      "        [ 0.1568, -0.0575,  0.0758,  ...,  0.1971, -0.0896, -0.0287],\n",
      "        [ 0.0813,  0.0294,  0.1618,  ..., -0.1842, -0.0384,  0.0101],\n",
      "        ...,\n",
      "        [-0.0584, -0.1553,  0.1042,  ...,  0.0577, -0.1791, -0.1820],\n",
      "        [ 0.0628,  0.0894, -0.1592,  ...,  0.1658, -0.0228,  0.0307],\n",
      "        [-0.1473,  0.1498, -0.0926,  ..., -0.1790, -0.0620, -0.1978]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1422], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1072], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0462, 0.0000, 0.0396, 0.0541, 0.0359, 0.0499, 0.0158, 0.0332, 0.0488,\n",
      "         0.0676, 0.1072, 0.0330, 0.0214, 0.0366, 0.0000, 0.0392, 0.0194, 0.0570,\n",
      "         0.0813, 0.0531, 0.0000, 0.0458, 0.0000, 0.0464, 0.0686]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([80.1061], device='cuda:0')\n",
      "loss=tensor(6394.2251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 0.,  0.,  0., 10.,  0.],\n",
      "         [ 0.,  0.,  5.,  1.,  0.],\n",
      "         [ 0.,  9.,  0.,  0.,  8.],\n",
      "         [ 3., 12.,  0.,  0.,  0.],\n",
      "         [ 8.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[5.]], device='cuda:0'), tensor([10], device='cuda:0'), tensor([-120.], device='cuda:0'), tensor([[[ 0.,  0.,  0., 10.,  0.],\n",
      "         [ 0.,  0.,  5.,  1.,  0.],\n",
      "         [ 5.,  9.,  0.,  0.,  8.],\n",
      "         [ 3., 12.,  0.,  0.,  0.],\n",
      "         [ 8.,  0.,  3.,  0.,  0.]]], device='cuda:0'), tensor([[1.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0115,  0.1840, -0.0072,  ...,  0.0785,  0.1167,  0.1648],\n",
      "        [ 0.1563, -0.0567,  0.0756,  ...,  0.1964, -0.0903, -0.0288],\n",
      "        [ 0.0813,  0.0303,  0.1620,  ..., -0.1842, -0.0377,  0.0101],\n",
      "        ...,\n",
      "        [-0.0585, -0.1556,  0.1041,  ...,  0.0577, -0.1798, -0.1822],\n",
      "        [ 0.0627,  0.0886, -0.1594,  ...,  0.1661, -0.0220,  0.0306],\n",
      "        [-0.1473,  0.1489, -0.0927,  ..., -0.1791, -0.0622, -0.1987]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([0.1137], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([0.1724], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[0.0411, 0.0336, 0.1011, 0.0000, 0.1724, 0.0629, 0.0624, 0.0000, 0.0000,\n",
      "         0.0532, 0.0000, 0.0000, 0.0794, 0.0781, 0.0000, 0.0000, 0.0000, 0.0289,\n",
      "         0.0479, 0.0610, 0.0000, 0.1046, 0.0000, 0.0451, 0.0284]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([-119.8293], device='cuda:0')\n",
      "loss=tensor(14386.3330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "Learning\n",
      "=========\n",
      "\n",
      "sample (tensor([[[ 4.,  2.,  9., 12.,  4.],\n",
      "         [ 8.,  0.,  5.,  7., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [11.,  4.,  2.,  1.,  6.],\n",
      "         [10.,  2.,  3., 10., 13.]]], device='cuda:0'), tensor([[12.]], device='cuda:0'), tensor([6], device='cuda:0'), tensor([-20.], device='cuda:0'), tensor([[[ 4.,  2.,  9., 12.,  4.],\n",
      "         [ 8., 12.,  5.,  7., 11.],\n",
      "         [ 5.,  8., 12.,  6.,  9.],\n",
      "         [11.,  4.,  2.,  1.,  6.],\n",
      "         [10.,  2.,  3., 10., 13.]]], device='cuda:0'), tensor([[7.]], device='cuda:0'))\n",
      "self.policy_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0114,  0.1839, -0.0073,  ...,  0.0786,  0.1169,  0.1646],\n",
      "        [ 0.1559, -0.0560,  0.0754,  ...,  0.1957, -0.0909, -0.0288],\n",
      "        [ 0.0814,  0.0312,  0.1621,  ..., -0.1841, -0.0370,  0.0102],\n",
      "        ...,\n",
      "        [-0.0586, -0.1559,  0.1040,  ...,  0.0576, -0.1805, -0.1824],\n",
      "        [ 0.0625,  0.0879, -0.1597,  ...,  0.1664, -0.0214,  0.0305],\n",
      "        [-0.1473,  0.1481, -0.0927,  ..., -0.1792, -0.0623, -0.1995]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "self.target_net.pipe[0].weight=Parameter containing:\n",
      "tensor([[ 0.0199,  0.1933,  0.0048,  ...,  0.0792,  0.1091,  0.1933],\n",
      "        [ 0.1463, -0.0724,  0.0615,  ...,  0.1861, -0.0947, -0.0113],\n",
      "        [ 0.0791,  0.0174,  0.1609,  ..., -0.1782, -0.0468,  0.0235],\n",
      "        ...,\n",
      "        [-0.0463, -0.1452,  0.1129,  ...,  0.0521, -0.1706, -0.1463],\n",
      "        [ 0.0761,  0.1072, -0.1423,  ...,  0.1711, -0.0177,  0.0158],\n",
      "        [-0.1507,  0.1582, -0.0730,  ..., -0.1720, -0.0550, -0.1824]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "q_values.shape=torch.Size([1])\n",
      "\tq_values=tensor([1.], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "action_batch.shape=torch.Size([1])\n",
      "next_q_values.shape=torch.Size([1])\n",
      "\tnext_q_values=tensor([nan], device='cuda:0')\n",
      "\t\tself.target_net(next_state_batch, next_card_batch)=tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "expected_q_values.shape=torch.Size([1])\n",
      "\texpected_q_values=tensor([nan], device='cuda:0')\n",
      "loss=tensor(nan, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter probs (Tensor of shape (1, 25)) of distribution Categorical(probs: torch.Size([1, 25])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n         nan]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[324], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Play the moves until the end\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m---> 13\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(action) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(action\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[323], line 19\u001b[0m, in \u001b[0;36mAgent.act\u001b[0;34m(self, state, card)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     18\u001b[0m     distr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net(state, card)\n\u001b[0;32m---> 19\u001b[0m     distr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     sample \u001b[38;5;241m=\u001b[39m distr\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "File \u001b[0;32m~/fi/uiprojekt/venv/lib/python3.11/site-packages/torch/distributions/categorical.py:66\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     65\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fi/uiprojekt/venv/lib/python3.11/site-packages/torch/distributions/distribution.py:62\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 62\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter probs (Tensor of shape (1, 25)) of distribution Categorical(probs: torch.Size([1, 25])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n         nan]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "def _tensor(x):\n",
    "    return torch.tensor([x], device=dev, dtype=torch.float32)\n",
    "\n",
    "\n",
    "for i in trange(config[\"episodes\"], desc=\"Episode\"):\n",
    "    # Reset the environment\n",
    "    state, card = map(_tensor, env.reset())\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    # Play the moves until the end\n",
    "    while not done:\n",
    "        action = agent.act(state, card)\n",
    "        assert len(action) == 1\n",
    "        \n",
    "        row, col = divmod(action.item(), 5)\n",
    "        next_state, reward, done, _ = env.step((row, col))\n",
    "        (next_state, next_card), reward = map(_tensor, next_state), _tensor(reward)\n",
    "        \n",
    "        agent.memory.push(state, card, action, next_state, next_card, reward)\n",
    "        agent.learn()\n",
    "        state, card = next_state, next_card\n",
    "        score += reward.item()\n",
    "        \n",
    "    # Update\n",
    "    if (i + 1) % config[\"decay_epochs\"] == 0:\n",
    "        agent.update_target_network()\n",
    "        agent.decay_epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26540dd6-4be5-47b2-86fa-cfb7f529e327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.policy_net.pipe[0].weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7f3ee5be-27bb-4582-84a7-ce4ee2fc7fbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected parameter probs (Tensor of shape (1, 25)) of distribution Categorical(probs: torch.Size([1, 25])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n         nan]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[258], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcard\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[253], line 19\u001b[0m, in \u001b[0;36mAgent.act\u001b[0;34m(self, state, card)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     18\u001b[0m     distr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net(state, card)\n\u001b[0;32m---> 19\u001b[0m     distr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     sample \u001b[38;5;241m=\u001b[39m distr\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "File \u001b[0;32m~/fi/uiprojekt/venv/lib/python3.11/site-packages/torch/distributions/categorical.py:66\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     65\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fi/uiprojekt/venv/lib/python3.11/site-packages/torch/distributions/distribution.py:62\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 62\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter probs (Tensor of shape (1, 25)) of distribution Categorical(probs: torch.Size([1, 25])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n         nan]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "agent.act(state, card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "94b564cd-2df1-4d5e-8e16-122e183fd540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  5.,  0.,  6.,  0.],\n",
       "         [ 0.,  0.,  0.,  8.,  0.],\n",
       "         [ 5.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 10.,  0.,  0.],\n",
       "         [ 0.,  0.,  3.,  0.,  7.]]], device='cuda:0')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "74cf32a3-0ed0-4bb7-aac5-6475caba826c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.]], device='cuda:0')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7253f953-76a1-42be-b897-74dcc56ed83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4f171ef6-dbeb-458a-ba46-408629daa67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0]],\n",
       " [5])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfef056-20bc-4690-9344-74b77d3351b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556f993-a096-468a-8714-46b7d5bdde0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
